{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "absolute_path = \"C:\\\\Users\\\\tykun\\\\OneDrive\\\\Documents\\\\SchoolDocs\\\\VSCodeProjects\\\\connectedData\\\\board_analysis\\\\\"\n",
    "altered_dataframes = \"altered_dataframes\\\\\"\n",
    "board_dataframes = \"board_dataframes\\\\\"\n",
    "final_scripts = \"final_scripts\\\\\"\n",
    "regression = \"regression\\\\\"\n",
    "normalized_dataframes = \"normalized_dataframes\\\\\"\n",
    "\n",
    "\n",
    "years = [\"1999\", \"2000\", \"2005\", \"2007\", \"2008\", \"2009\", \"2010\", \"2011\", \"2013\", \"2018\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#time invariant dfs\n",
    "affiliation_df = pd.read_csv(f\"{absolute_path}{final_scripts}{regression}regression_stats\\\\affiliation_systems.csv\")\n",
    "original_affiliation_df  = pd.read_csv(f\"{absolute_path}{final_scripts}{regression}regression_stats\\\\affiliation_original.csv\")\n",
    "\n",
    "#create a dictionary mapping state system -> institutions within the system\n",
    "affiliation_dict = affiliation_df.groupby(\"StateSystem\")[\"AffiliationId\"].apply(list).to_dict()\n",
    "\n",
    "affiliation_inverted = {\n",
    "    aff_id: state_system\n",
    "    for state_system, aff_ids in affiliation_dict.items()\n",
    "    for aff_id in aff_ids\n",
    "}\n",
    "\n",
    "# for key, val in affiliation_dict.items():\n",
    "#     print(key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_non_samples(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Filter the DataFrame to include only rows where 'PrimarySample' is True.\"\"\"\n",
    "    return df[df['PrimarySample'] == True]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''map the state systems to an affiliation id if they have one'''\n",
    "\n",
    "matched_df = original_affiliation_df[original_affiliation_df[\"FullName\"].isin(affiliation_dict.keys())].copy()\n",
    "\n",
    "matched_df[\"StateSystem\"] = matched_df[\"FullName\"]\n",
    "\n",
    "mapping_df = matched_df[[\"StateSystem\", \"AffiliationId\"]]\n",
    "\n",
    "mapping_df = mapping_df.drop_duplicates()\n",
    "\n",
    "\n",
    "mapping_df.to_csv(f\"{absolute_path}{final_scripts}{regression}regression_stats\\\\system_mapping.csv\", index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{127339247.0: [184813773, 67328108, 67328108, 142934699, 142934699, 142934699, 59897056, 59897056, 43369023, 43369023, 26538001, 71838634], 174216632.0: [125687163, 125687163, 125687163], 4210131357.0: [92446798, 92446798, 92446798, 92446798], 4210165361.0: [120156002, 106969075, 155093810], 2801365651.0: [189590672, 146416000, 39587148], 4210141039.0: [61937129, 99041443, 368840534, 44854399], 4210127926.0: [57328836, 24571045, 24571045], 29957033.0: [200885203, 161171246, 161171246], 1327163397.0: [392282, 392282, 392282, 392282, 123946342, 123946342, 123946342, 123946342, 63190737, 63190737, 63190737, 63190737, 59553526, 59553526, 59553526, 59553526, 59553526], 2801649442.0: [8248082, 63772739, 19700959, 106165777, 33213144, 11874761, 2613432], 173268674.0: [75063564, 91045830, 91045830, 91045830, 206651237, 206651237, 96749437, 96749437, 164185940, 164185940, 181414168, 181414168], 2801273398.0: [191429286, 13511017, 13511017, 13511017, 13511017], 4210088475.0: [12315562, 926076166], 68260882.0: [133999245, 133999245, 134113660, 134113660], 2800507078.0: [32389192, 32389192, 82495205, 82495205, 17301866, 17301866, 17301866, 17301866], 2802090665.0: [141472210], 2799691083.0: [78715868, 78715868, 78715868, 102401767, 79620101], 2803209242.0: [95457486, 95457486, 84218800, 84218800, 204250578, 204250578, 161318765, 161318765, 156087764, 156087764, 103635307, 103635307, 36258959, 36258959, 180670191, 154570441, 185103710], 2802236040.0: [188538660, 188538660, 888729015, 888729015, 921990950, 921990950, 921990950, 921990950], 1331384533.0: [117965899, 117965899], 2801525821.0: [44461941], 2801919071.0: [39422238, 39422238, 157725225, 157725225], 2799628689.0: [919208787, 79516672, 79516672, 79516672, 79516672], 2802397601.0: [7947594, 7947594, 7947594], 2802841742.0: [24603500, 24603500, 33434090, 33434090, 100633361, 100633361, 133738476, 133738476, 166722992, 166722992, 166722992], 4777552.0: [76835614, 76835614, 75421653, 75421653, 20382870, 20382870, 208333798, 208333798], 2802450327.0: [114395901, 114395901, 114395901, 122266389, 122266389, 59130452], 4210158053.0: [186335123, 35777872, 137902535, 114027177, 102149020, 169335092, 153901656, 153901656], 2802090120.0: [123534392], 2799495847.0: [75027704, 160606119, 160606119], 16452829.0: [189196454, 86519309, 2802326326, 2802326326, 162577319, 164936912, 164936912, 45438204, 221716585, 4210094379, 4210094379, 919571938, 165951966, 165951966, 55302922], 1304256225.0: [135310074, 135310074, 43579087, 43579087], 1289702989.0: [130701444, 39815113, 181565077, 172980758, 165733156], 1317227900.0: [126744593, 79272384, 66946132, 22407884, 22407884], 2800453862.0: [161057412, 161057412], 2802096936.0: [157417397, 102607778, 149910238, 83328450, 52357470, 52357470, 4210106879, 110152177, 63135867, 90871651, 19648265]}\n",
      "{'Arizona Board of Regents': [55732556, 203172682, 138006243], 'Indiana University System': [4210119109, 55769427], 'Oklahoma State System of Higher Education': [115475287, 8692664], 'Tennessee Board of Regents': [119443389, 169615421, 75256744, 63920570, 94658018]}\n"
     ]
    }
   ],
   "source": [
    "system_id_map = {}\n",
    "nan_id_map = {}\n",
    "\n",
    "for _, row in mapping_df.iterrows():\n",
    "    state_system = row[\"StateSystem\"]\n",
    "    board_aff_id = row[\"AffiliationId\"]\n",
    "    if pd.isna(board_aff_id):\n",
    "        nan_id_map[state_system] = affiliation_dict.get(state_system, [])\n",
    "    else:\n",
    "        system_id_map[board_aff_id] = affiliation_dict.get(state_system, [])\n",
    "\n",
    "# Display the resulting dictionary\n",
    "print(system_id_map)\n",
    "print(nan_id_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2011: Overwriting group for affiliation id 57328836\n",
      "2011: Overwriting group for affiliation id 99041443\n",
      "2013: Overwriting group for affiliation id 57328836\n",
      "2013: Overwriting group for affiliation id 99041443\n",
      "2018: Overwriting group for affiliation id 76835614\n",
      "2018: Overwriting group for affiliation id 76835614\n"
     ]
    }
   ],
   "source": [
    "#create a mapping from AffiliationId to FullName from original_affiliation_df\n",
    "inst_mapping = dict(zip(original_affiliation_df[\"AffiliationId\"], original_affiliation_df[\"FullName\"]))\n",
    "primary_sample_mapping = dict(\n",
    "    original_affiliation_df.drop_duplicates(\"AffiliationId\").set_index(\"AffiliationId\")[\"PrimarySample\"]\n",
    ")\n",
    "\n",
    "for year in years:\n",
    "    board_path = os.path.join(absolute_path, board_dataframes, f\"{year}_boards.csv\")\n",
    "    double_board_path = os.path.join(absolute_path, board_dataframes, f\"{year}_double_board.csv\")\n",
    "    board_df = pd.read_csv(board_path)\n",
    "    double_board_df = pd.read_csv(double_board_path)\n",
    "    board_df['AffiliationId'] = board_df['AffiliationId'].fillna(0)\n",
    "    double_board_df['AffiliationId'] = double_board_df['AffiliationId'].fillna(0)\n",
    "    #get set of existing affiliation ids from the boards to check if there is already a board when we expand\n",
    "    existing_affiliation_ids_board = set(board_df[\"AffiliationId\"].unique())\n",
    "    existing_affiliation_ids_double = set(double_board_df[\"AffiliationId\"].unique())\n",
    "\n",
    "\n",
    "    expanded_groups = []\n",
    "    for affiliation_id, group in board_df.groupby(\"AffiliationId\"):\n",
    "        expanded_groups.append(group)\n",
    "        #if the current institution is in the state system map\n",
    "        if affiliation_id in system_id_map:\n",
    "            for new_affiliation_id in system_id_map[affiliation_id]:\n",
    "                #If the new affiliation id already exists\n",
    "                if new_affiliation_id in existing_affiliation_ids_board:\n",
    "                    # For years greater than 2010, overwrite the existing group (these schools are always reported under the same board. we overwrite because the board is incorrect initially)\n",
    "                    if int(year) > 2010:\n",
    "                        expanded_groups = [g for g in expanded_groups if g[\"AffiliationId\"].iloc[0] != new_affiliation_id]\n",
    "                        print(f\"{year}: Overwriting group for affiliation id {new_affiliation_id}\")\n",
    "                    else:\n",
    "                        # Otherwise, skip expanding this group (in the previous years, they report these boards separately a lot of the time)\n",
    "                        continue\n",
    "                new_group = group.copy()\n",
    "                new_group[\"AffiliationId\"] = new_affiliation_id\n",
    "                #lookup the institution name using the new affiliation id\n",
    "                new_inst = inst_mapping.get(new_affiliation_id, new_group[\"Institution\"].iloc[0])\n",
    "                new_group[\"Institution\"] = new_inst\n",
    "                expanded_groups.append(new_group)\n",
    "    expanded_board_df = pd.concat(expanded_groups, ignore_index=True)\n",
    "\n",
    "    #Process double_board_df similarly:\n",
    "    expanded_groups_db = []\n",
    "    for affiliation_id, group in double_board_df.groupby(\"AffiliationId\"):\n",
    "        expanded_groups_db.append(group)\n",
    "        if affiliation_id in system_id_map:\n",
    "            for new_affiliation_id in system_id_map[affiliation_id]:\n",
    "                if new_affiliation_id in existing_affiliation_ids_double:\n",
    "                    if int(year) > 2010:\n",
    "                        expanded_groups_db = [g for g in expanded_groups_db if g[\"AffiliationId\"].iloc[0] != new_affiliation_id]\n",
    "                        print(f\"{year}: Overwriting double board group for affiliation id {new_affiliation_id}\")\n",
    "                    else:\n",
    "                        continue\n",
    "                new_group = group.copy()\n",
    "                new_group[\"AffiliationId\"] = new_affiliation_id\n",
    "                new_inst = inst_mapping.get(new_affiliation_id, new_group[\"Institution\"].iloc[0])\n",
    "                new_group[\"Institution\"] = new_inst\n",
    "                expanded_groups_db.append(new_group)\n",
    "    expanded_double_board_df = pd.concat(expanded_groups_db, ignore_index=True)\n",
    "\n",
    "    #Update PrimarySample column because when we map from the system -> new insittution, it says primary sample is false because the system itself is not a sample\n",
    "    expanded_board_df[\"PrimarySample\"] = expanded_board_df[\"AffiliationId\"].map(primary_sample_mapping)\n",
    "    expanded_double_board_df[\"PrimarySample\"] = expanded_double_board_df[\"AffiliationId\"].map(primary_sample_mapping)\n",
    "    \n",
    "    expanded_board_df.sort_values(by=['Institution'], inplace=True)\n",
    "    expanded_double_board_df.sort_values(by=['Institution'], inplace=True)\n",
    "\n",
    "    expanded_board_df.to_csv(os.path.join(absolute_path, f\"{final_scripts}{regression}regression_boards\", f\"{year}_boards_regression.csv\"), index=False)\n",
    "    expanded_double_board_df.to_csv(os.path.join(absolute_path, f\"{final_scripts}{regression}regression_boards\", f\"{year}_double_boards_regression.csv\"), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1999: Expanding for institution 'Tennessee Board Of Regents' (normalized: 'Tennessee Board Of Regents')\n",
      "2000: Expanding for institution 'Indiana University System' (normalized: 'Indiana University System')\n",
      "2005: Expanding for institution 'Indiana University System' (normalized: 'Indiana University System')\n",
      "2007: Expanding for institution 'Arizona Board Of Regents' (normalized: 'Arizona Board Of Regents')\n",
      "2007: Expanding for institution 'Indiana University System' (normalized: 'Indiana University System')\n",
      "2008: Expanding for institution 'Indiana University System' (normalized: 'Indiana University System')\n",
      "2009: Expanding for institution 'Indiana University System' (normalized: 'Indiana University System')\n",
      "2010: Expanding for institution 'Arizona Board Of Regents' (normalized: 'Arizona Board Of Regents')\n",
      "2010: Expanding for institution 'Indiana University System' (normalized: 'Indiana University System')\n",
      "2010: Expanding for institution 'Oklahoma State System Of Higher Education' (normalized: 'Oklahoma State System Of Higher Education')\n",
      "2010: Expanding for institution 'Tennessee Board Of Regents' (normalized: 'Tennessee Board Of Regents')\n",
      "2011: Expanding for institution 'Arizona Board Of Regents' (normalized: 'Arizona Board Of Regents')\n",
      "2011: Expanding for institution 'Indiana University System' (normalized: 'Indiana University System')\n",
      "2011: Expanding for institution 'Oklahoma State System Of Higher Education' (normalized: 'Oklahoma State System Of Higher Education')\n",
      "2011: Expanding for institution 'Tennessee Board Of Regents' (normalized: 'Tennessee Board Of Regents')\n",
      "2013: Expanding for institution 'Arizona Board Of Regents' (normalized: 'Arizona Board Of Regents')\n",
      "2013: Overwriting group for affiliation id 55732556\n",
      "2013: Expanding for institution 'Indiana University System' (normalized: 'Indiana University System')\n",
      "2013: Expanding for institution 'Oklahoma State System Of Higher Education' (normalized: 'Oklahoma State System Of Higher Education')\n",
      "2013: Expanding for institution 'Tennessee Board Of Regents' (normalized: 'Tennessee Board Of Regents')\n",
      "2018: Expanding for institution 'Arizona Board Of Regents' (normalized: 'Arizona Board Of Regents')\n",
      "2018: Expanding for institution 'Indiana University System' (normalized: 'Indiana University System')\n",
      "2018: Expanding for institution 'Oklahoma State System Of Higher Education' (normalized: 'Oklahoma State System Of Higher Education')\n",
      "2018: Expanding for institution 'Tennessee Board Of Regents' (normalized: 'Tennessee Board Of Regents')\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "check for system-> institutions by the institution name\n",
    "This is a backup, because some of the systems dont have an affiliation id\n",
    "it only edits the remaining systems that have yet to be mapped, doesnt edit anything else\n",
    "'''\n",
    "\n",
    "'''\n",
    "check for system-> institutions by the institution name\n",
    "This is a backup, because some of the systems dont have an affiliation id\n",
    "it only edits the remaining systems that have yet to be mapped, doesnt edit anything else\n",
    "'''\n",
    "\n",
    "def normalize_institution(s):\n",
    "    # Remove punctuation, strip whitespace, and convert to title case\n",
    "    return s.strip().translate(str.maketrans('', '', string.punctuation)).title()\n",
    "\n",
    "#Create a normalized version of nan_id_map using the normalized institution name as key.\n",
    "normalized_nan_id_map = {normalize_institution(key): value for key, value in nan_id_map.items()}\n",
    "\n",
    "inst_mapping = dict(zip(original_affiliation_df[\"AffiliationId\"], original_affiliation_df[\"FullName\"]))\n",
    "primary_sample_mapping = dict(\n",
    "    original_affiliation_df.drop_duplicates(\"AffiliationId\").set_index(\"AffiliationId\")[\"PrimarySample\"]\n",
    ")\n",
    "\n",
    "for year in years:\n",
    "    board_path = os.path.join(absolute_path, f\"{final_scripts}{regression}regression_boards\", f\"{year}_boards_regression.csv\")\n",
    "    double_board_path = os.path.join(absolute_path, f\"{final_scripts}{regression}regression_boards\", f\"{year}_double_boards_regression.csv\")\n",
    "    board_df = pd.read_csv(board_path)\n",
    "    double_board_df = pd.read_csv(double_board_path)\n",
    "    \n",
    "    #get the set of existing affiliation ids from the original board data.\n",
    "    existing_affiliation_ids_board = set(board_df[\"AffiliationId\"].unique())\n",
    "    existing_affiliation_ids_double = set(double_board_df[\"AffiliationId\"].unique())\n",
    "    \n",
    "    # Process board_df:\n",
    "    expanded_groups = []\n",
    "    for institution, group in board_df.groupby(\"Institution\"):\n",
    "        expanded_groups.append(group)\n",
    "        norm_institution = normalize_institution(institution)\n",
    "        #expand the board if exists in the systems dict\n",
    "        if norm_institution in normalized_nan_id_map:\n",
    "            print(f\"{year}: Expanding for institution '{institution}' (normalized: '{norm_institution}')\")\n",
    "            for new_affiliation_id in normalized_nan_id_map[norm_institution]:\n",
    "                #Check if a group for this new affiliation id already exists.\n",
    "                if new_affiliation_id in existing_affiliation_ids_board:\n",
    "                    if int(year) > 2010:\n",
    "                        expanded_groups = [g for g in expanded_groups if g[\"AffiliationId\"].iloc[0] != new_affiliation_id]\n",
    "                        print(f\"{year}: Overwriting group for affiliation id {new_affiliation_id}\")\n",
    "                    else:\n",
    "                        continue\n",
    "                new_group = group.copy()\n",
    "                new_group[\"AffiliationId\"] = new_affiliation_id\n",
    "                new_inst = inst_mapping.get(new_affiliation_id, institution)\n",
    "                new_group[\"Institution\"] = new_inst\n",
    "                expanded_groups.append(new_group)\n",
    "    expanded_board_df = pd.concat(expanded_groups, ignore_index=True)\n",
    "    \n",
    "    #Process double_board_df similarly:\n",
    "    expanded_groups_db = []\n",
    "    for institution, group in double_board_df.groupby(\"Institution\"):\n",
    "        expanded_groups_db.append(group)\n",
    "        norm_institution = normalize_institution(institution)\n",
    "        if norm_institution in normalized_nan_id_map:\n",
    "            for new_affiliation_id in normalized_nan_id_map[norm_institution]:\n",
    "                if new_affiliation_id in existing_affiliation_ids_double:\n",
    "                    if int(year) > 2010:\n",
    "                        expanded_groups_db = [g for g in expanded_groups_db \n",
    "                                              if g[\"AffiliationId\"].iloc[0] != new_affiliation_id]\n",
    "                        print(f\"{year}: Overwriting double board group for affiliation id {new_affiliation_id}\")\n",
    "                    else:\n",
    "                        continue\n",
    "                new_group = group.copy()\n",
    "                new_group[\"AffiliationId\"] = new_affiliation_id\n",
    "                new_inst = inst_mapping.get(new_affiliation_id, institution)\n",
    "                new_group[\"Institution\"] = new_inst\n",
    "                expanded_groups_db.append(new_group)\n",
    "    expanded_double_board_df = pd.concat(expanded_groups_db, ignore_index=True)\n",
    "    \n",
    "    expanded_board_df[\"PrimarySample\"] = expanded_board_df[\"AffiliationId\"].map(primary_sample_mapping)\n",
    "    expanded_double_board_df[\"PrimarySample\"] = expanded_double_board_df[\"AffiliationId\"].map(primary_sample_mapping)\n",
    "    \n",
    "    expanded_board_df.sort_values(by=['Institution'], inplace=True)\n",
    "    expanded_double_board_df.sort_values(by=['Institution'], inplace=True)\n",
    "\n",
    "    expanded_board_df = expanded_board_df[expanded_board_df[\"AffiliationId\"] != 0]\n",
    "    expanded_double_board_df = expanded_double_board_df[expanded_double_board_df[\"AffiliationId\"] != 0]\n",
    "    \n",
    "    expanded_board_df.to_csv(os.path.join(absolute_path, f\"{final_scripts}{regression}regression_boards\", f\"{year}_boards_regression.csv\"), index=False)\n",
    "    expanded_double_board_df.to_csv(os.path.join(absolute_path, f\"{final_scripts}{regression}regression_boards\", f\"{year}_double_boards_regression.csv\"), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '''\n",
    "# This code is essentially supposed to union the state system boards together when they are reported separately (pre 2009)\n",
    "# However, the boards seem to actually be separate a lot of the times, which i am confused by. Is the book wrong? \n",
    "#     Ohio state system reports under one board later on, but it seems like this is not what happens in real life\n",
    "#     Same thing with florida state? It says they started merging in 2003, but they dont actually have the same board until 2009 df\n",
    "# '''\n",
    "\n",
    "\n",
    "# # # Create a set of unique systems (each system is a set of affiliation IDs) from system_id_map.\n",
    "# unique_systems = set()\n",
    "# for vals in system_id_map.values():\n",
    "#     unique_systems.add(frozenset(vals))\n",
    "# unique_systems = [set(s) for s in unique_systems]  # Convert frozenset back to set for easier use\n",
    "\n",
    "# # We'll store a report of additions per system\n",
    "# system_report = {}\n",
    "\n",
    "# for year in years:\n",
    "#     board_path = os.path.join(absolute_path, board_dataframes, f\"{year}_boards.csv\")\n",
    "#     double_board_path = os.path.join(absolute_path, board_dataframes, f\"{year}_double_board.csv\")\n",
    "#     board_df = pd.read_csv(board_path)\n",
    "#     double_board_df = pd.read_csv(double_board_path)\n",
    "    \n",
    "#     # Make copies that we can update\n",
    "#     updated_board_df = board_df.copy()\n",
    "#     updated_double_board_df = double_board_df.copy()\n",
    "    \n",
    "#     # For reporting additions in this year\n",
    "#     year_report = {}\n",
    "    \n",
    "#     # Collect new rows for board_df in a list (to avoid repeated concat calls)\n",
    "#     new_rows = []\n",
    "    \n",
    "#     # --- Process board_df for system unioning ---\n",
    "#     for system in unique_systems:\n",
    "#         # Get all rows in the system (any institution whose AffiliationId is in the system)\n",
    "#         system_subset = updated_board_df[ updated_board_df[\"AffiliationId\"].isin(system) ]\n",
    "#         # Compute the union of board member names across the system\n",
    "#         union_names = set(system_subset[\"Name\"].unique())\n",
    "        \n",
    "#         # For each institution (target affiliation) in this system:\n",
    "#         for inst_id in system:\n",
    "#             inst_rows = updated_board_df[ updated_board_df[\"AffiliationId\"] == inst_id ]\n",
    "#             current_names = set(inst_rows[\"Name\"].unique())\n",
    "#             missing_names = union_names - current_names\n",
    "            \n",
    "#             current_count = len(inst_rows)\n",
    "#             # Only add if the missing names count would not exceed a 20% increase\n",
    "#             if current_count == 0 or len(missing_names) > 0.2 * current_count:\n",
    "#                 continue  # Skip unioning for this institution\n",
    "            \n",
    "#             added_count = 0\n",
    "#             # Use a representative row from the target institution to get institution-specific info\n",
    "#             rep_target = inst_rows.iloc[0].copy()\n",
    "#             for missing_name in missing_names:\n",
    "#                 # For board member–specific details, pick a representative row from the union where Name==missing_name\n",
    "#                 rep_union_rows = system_subset[ system_subset[\"Name\"] == missing_name ]\n",
    "#                 if rep_union_rows.empty:\n",
    "#                     continue\n",
    "#                 rep_union = rep_union_rows.iloc[0].copy()\n",
    "                \n",
    "#                 # Create new row: copy all board member–specific info from rep_union,\n",
    "#                 # but override institution-specific columns with the target institution's info.\n",
    "#                 new_row = rep_union.copy()\n",
    "#                 new_row[\"Name\"] = missing_name  # Should already be missing_name\n",
    "#                 new_row[\"Institution\"] = rep_target[\"Institution\"]\n",
    "#                 new_row[\"AffiliationId\"] = rep_target[\"AffiliationId\"]\n",
    "#                 new_row[\"carnegie_id\"] = rep_target[\"carnegie_id\"]\n",
    "#                 new_row[\"Added\"] = True  # Flag to indicate this row was added by unioning\n",
    "#                 new_rows.append(new_row)\n",
    "#                 added_count += 1\n",
    "#             if added_count > 0:\n",
    "#                 year_report.setdefault(inst_id, 0)\n",
    "#                 year_report[inst_id] += added_count\n",
    "    \n",
    "#     # Append the new rows (if any) to updated_board_df.\n",
    "#     if new_rows:\n",
    "#         new_rows_df = pd.DataFrame(new_rows)\n",
    "#         # Ensure new_rows_df has the same column order as updated_board_df\n",
    "#         new_rows_df = new_rows_df[updated_board_df.columns]\n",
    "#         updated_board_df = pd.concat([updated_board_df, new_rows_df], ignore_index=True)\n",
    "    \n",
    "#     # Remove any duplicates within each institution based on (\"AffiliationId\", \"Name\")\n",
    "#     updated_board_df = updated_board_df.drop_duplicates(subset=[\"AffiliationId\", \"Name\"])\n",
    "    \n",
    "#     # --- Process double_board_df similarly ---\n",
    "#     new_rows_db = []\n",
    "#     double_year_report = {}\n",
    "#     for system in unique_systems:\n",
    "#         system_subset_db = updated_double_board_df[ updated_double_board_df[\"AffiliationId\"].isin(system) ]\n",
    "#         union_names_db = set(system_subset_db[\"Name\"].unique())\n",
    "        \n",
    "#         for inst_id in system:\n",
    "#             inst_rows_db = updated_double_board_df[ updated_double_board_df[\"AffiliationId\"] == inst_id ]\n",
    "#             current_names_db = set(inst_rows_db[\"Name\"].unique())\n",
    "#             missing_names_db = union_names_db - current_names_db\n",
    "            \n",
    "#             current_count_db = len(inst_rows_db)\n",
    "#             if current_count_db == 0 or len(missing_names_db) > 0.2 * current_count_db:\n",
    "#                 continue\n",
    "            \n",
    "#             added_count = 0\n",
    "#             rep_target_db = inst_rows_db.iloc[0].copy()\n",
    "#             for missing_name in missing_names_db:\n",
    "#                 rep_union_rows_db = system_subset_db[ system_subset_db[\"Name\"] == missing_name ]\n",
    "#                 if rep_union_rows_db.empty:\n",
    "#                     continue\n",
    "#                 rep_union_db = rep_union_rows_db.iloc[0].copy()\n",
    "#                 new_row_db = rep_union_db.copy()\n",
    "#                 new_row_db[\"Name\"] = missing_name\n",
    "#                 new_row_db[\"Institution\"] = rep_target_db[\"Institution\"]\n",
    "#                 new_row_db[\"AffiliationId\"] = rep_target_db[\"AffiliationId\"]\n",
    "#                 new_row_db[\"carnegie_id\"] = rep_target_db[\"carnegie_id\"]\n",
    "#                 new_row_db[\"Added\"] = True\n",
    "#                 new_rows_db.append(new_row_db)\n",
    "#                 added_count += 1\n",
    "#             if added_count > 0:\n",
    "#                 double_year_report.setdefault(inst_id, 0)\n",
    "#                 double_year_report[inst_id] += added_count\n",
    "                \n",
    "#     if new_rows_db:\n",
    "#         new_rows_db_df = pd.DataFrame(new_rows_db)\n",
    "#         new_rows_db_df = new_rows_db_df[updated_double_board_df.columns]\n",
    "#         updated_double_board_df = pd.concat([updated_double_board_df, new_rows_db_df], ignore_index=True)\n",
    "#     updated_double_board_df = updated_double_board_df.drop_duplicates(subset=[\"AffiliationId\", \"Name\"])\n",
    "    \n",
    "#     # Print report for this year\n",
    "#     print(f\"Year {year} board expansion report:\")\n",
    "#     for inst_id, count in year_report.items():\n",
    "#         print(f\" - Institution with AffiliationId {inst_id}: added {count} board members.\")\n",
    "#     print(f\"Year {year} double board expansion report:\")\n",
    "#     for inst_id, count in double_year_report.items():\n",
    "#         print(f\" - Institution with AffiliationId {inst_id}: added {count} board members.\")\n",
    "    \n",
    "#     # Sort the DataFrames by Institution and AffiliationId before saving\n",
    "#     updated_board_df.sort_values(by=['Institution', 'AffiliationId'], inplace=True)\n",
    "#     updated_double_board_df.sort_values(by=['Institution', 'AffiliationId'], inplace=True)\n",
    "    \n",
    "#     # Write the updated DataFrames to CSV\n",
    "#     updated_board_df.to_csv(os.path.join(absolute_path, f\"{final_scripts}{regression}regression_boards\", f\"{year}_boards_regression.csv\"), index=False)\n",
    "#     updated_double_board_df.to_csv(os.path.join(absolute_path, f\"{final_scripts}{regression}regression_boards\", f\"{year}_double_boards_regression.csv\"), index=False)\n",
    "    \n",
    "#     # Store the report for this year\n",
    "#     system_report[year] = {\"boards\": year_report, \"double_boards\": double_year_report}\n",
    "\n",
    "# print(\"Overall system expansion report:\", system_report)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projectEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
