{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File Paths\n",
    "absolute_path = \"C:\\\\Users\\\\tykun\\\\\\OneDrive\\\\Documents\\\\SchoolDocs\\VSCodeProjects\\\\connectedData\\\\board_analysis\\\\\"\n",
    "altered_dataframes = \"altered_dataframes\\\\\"\n",
    "gpt_dataframes = \"gpt_dataframes\\\\\"\n",
    "graphs = \"graphs\\\\\"\n",
    "scripts =  \"scripts\\\\\"\n",
    "board_dataframes = \"board_dataframes\\\\\"\n",
    "temporary = \"temporary_data\\\\\"\n",
    "final_scripts = \"final_scripts\\\\\"\n",
    "normalized_dataframes = \"normalized_dataframes\\\\\"\n",
    "college_matching = \"college_matching\\\\\"\n",
    "regression = \"regression\\\\\"\n",
    "normalized_dataframes = \"normalized_dataframes\\\\\"\n",
    "normalized_regression_boards = \"normalized_regression_boards\\\\\"\n",
    "network = \"network\\\\\"\n",
    "network_boards = \"network_boards\\\\\"\n",
    "\n",
    "altered_dataframe_path = f\"{absolute_path}{altered_dataframes}\"\n",
    "gpt_dataframe_path = f\"{absolute_path}{gpt_dataframes}\" \n",
    "graph_path = f\"{absolute_path}{graphs}\"\n",
    "script_path = f\"{absolute_path}{scripts}\"\n",
    "boards_path = f\"{absolute_path}{board_dataframes}\"\n",
    "temporary_data_path = f\"{absolute_path}{temporary}\"\n",
    "regression_path =  f\"{absolute_path}{final_scripts}{regression}\"\n",
    "regression_boards_path = f\"{regression_path}{normalized_regression_boards}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2003-2019\n",
    "shanghai_rankings_path = \"C:\\\\Users\\\\tykun\\\\OneDrive\\\\Documents\\\\SchoolDocs\\\\VSCodeProjects\\\\connectedData\\\\board_analysis\\\\final_scripts\\\\rankings\\\\ShanghaiUniversityRanking\\\\\"\n",
    "#2011-2020\n",
    "times_rankings_path = \"C:\\\\Users\\\\tykun\\\\OneDrive\\\\Documents\\\\SchoolDocs\\\\VSCodeProjects\\\\connectedData\\\\board_analysis\\\\final_scripts\\\\rankings\\\\TimesUniversityRankings\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "times_file_path = os.path.join(times_rankings_path, \"TimesWorldRanking2011.hdf\")\n",
    "times_rankings = pd.read_hdf(times_file_path)\n",
    "# print(times_rankings.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Rank', 'FullName', 'href', 'Country', 'TotalScore', 'Alumni', 'Award',\n",
      "       'HiCi', 'N&S', 'Pub', 'PCP', 'AffiliationID'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "shanghai_file_path = os.path.join(shanghai_rankings_path, \"ShanghaiUniversityRanking_ShanghaiRanking2004.hdf\")\n",
    "shanghai_rankings = pd.read_hdf(shanghai_file_path)\n",
    "\n",
    "print(shanghai_rankings.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Year', 'Institution', 'AffiliationId', 'female_president',\n",
      "       'PrimarySample', 'total_members', 'total_ethnicity', 'board_turnover',\n",
      "       'carnegie_id', 'state', 'control', 'StateSystem', 'region',\n",
      "       'num_billionaires', 'student.women', 'faculty.women',\n",
      "       'faculty.race_ethnicity.white', 'student.size',\n",
      "       'cost.tuition.out_of_state', 'school.faculty_salary', 'RD_expenditure',\n",
      "       'female_proportion', 'poc_proportion', 'billionaire_proportion',\n",
      "       'eigenvector', 'betweenness', 'degree', 'strength', 'clustering',\n",
      "       'Rank'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "university_stats_path = os.path.join(regression_path, \"regression_stats\", \"regression_university_board_statistics.csv\")\n",
    "df = pd.read_csv(university_stats_path)\n",
    "df[\"Year\"] = df[\"Year\"].astype(str)\n",
    "\n",
    "if \"Rank\" in df.columns:\n",
    "    df = df.drop(\"Rank\", axis=1)\n",
    "\n",
    "valid_years = set(str(year) for year in range(2003, 2020))\n",
    "df[\"ShanghaiYear\"] = df[\"Year\"].apply(lambda y: y if y in valid_years else \"2003\")\n",
    "\n",
    "merged_list = []\n",
    "for sh_year in sorted(df[\"ShanghaiYear\"].unique()):\n",
    "    shanghai_file_path = os.path.join(shanghai_rankings_path, f\"ShanghaiUniversityRanking_ShanghaiRanking{sh_year}.hdf\")\n",
    "    shanghai_rankings = pd.read_hdf(shanghai_file_path)\n",
    "    shanghai_rankings.rename(columns={\"AffiliationID\": \"AffiliationId\"}, inplace=True)\n",
    "    shanghai_subset = shanghai_rankings[[\"AffiliationId\", \"Rank\"]].copy()\n",
    "    shanghai_subset[\"ShanghaiYear\"] = sh_year  \n",
    "\n",
    "    subset = df[df[\"ShanghaiYear\"] == sh_year].copy()\n",
    "    merged = pd.merge(subset, shanghai_subset, on=[\"AffiliationId\", \"ShanghaiYear\"], how=\"left\")\n",
    "    merged_list.append(merged)\n",
    "\n",
    "merged_df = pd.concat(merged_list, ignore_index=True)\n",
    "mapping_2003 = merged_df.loc[merged_df[\"Year\"] == \"2003\"].set_index(\"AffiliationId\")[\"Rank\"]\n",
    "\n",
    "def fill_rank(row):\n",
    "    if pd.isna(row[\"Rank\"]) and int(row[\"Year\"]) < 2003:\n",
    "        if row[\"AffiliationId\"] in mapping_2003.index:\n",
    "            return mapping_2003.loc[row[\"AffiliationId\"]]\n",
    "    return row[\"Rank\"]\n",
    "\n",
    "merged_df[\"Rank\"] = merged_df.apply(fill_rank, axis=1)\n",
    "merged_df.drop(\"ShanghaiYear\", axis=1, inplace=True)\n",
    "university_board_statistics_df = merged_df.copy()\n",
    "\n",
    "def clean_rank(x):\n",
    "    if pd.isna(x):\n",
    "        return np.nan\n",
    "    x_str = str(x)\n",
    "    if '-' in x_str:\n",
    "        x_str = x_str.split('-')[0]\n",
    "    try:\n",
    "        return float(x_str)\n",
    "    except:\n",
    "        return np.nan\n",
    "    \n",
    "university_board_statistics_df[\"Rank\"] = university_board_statistics_df[\"Rank\"].apply(clean_rank)\n",
    "university_board_statistics_df[\"Rank\"] = university_board_statistics_df[\"Rank\"].fillna(500)\n",
    "university_board_statistics_df[\"Rank\"] = university_board_statistics_df[\"Rank\"].astype(int)\n",
    "print(university_board_statistics_df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_rank(x):\n",
    "    if pd.isna(x):\n",
    "        return 101\n",
    "    x_str = str(x)\n",
    "    if '-' in x_str:\n",
    "        x_str = x_str.split('-')[0]\n",
    "    try:\n",
    "        rank_val = float(x_str)\n",
    "    except ValueError:\n",
    "        return '101'\n",
    "    if rank_val <= 10:\n",
    "        return '1 to 10'\n",
    "    elif rank_val <= 30:\n",
    "        return '11 to 30'\n",
    "    elif rank_val <= 80:\n",
    "        return '31 to 80'\n",
    "    elif rank_val <= 100:\n",
    "        return '81 to 100'\n",
    "    else:\n",
    "        return '101'\n",
    "\n",
    "university_board_statistics_df[\"Rank\"] = university_board_statistics_df[\"Rank\"].apply(classify_rank)\n",
    "university_board_statistics_df.drop_duplicates(inplace=True)\n",
    "university_board_statistics_df.to_csv(university_stats_path, index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projectEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
