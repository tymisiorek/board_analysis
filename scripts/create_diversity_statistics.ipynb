{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\tykun\\OneDrive\\Documents\\SchoolDocs\\VSCodeProjects\\projectEnv\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter, defaultdict\n",
    "from matplotlib.lines import Line2D\n",
    "from nameparser import HumanName\n",
    "import gender_guesser.detector as gender\n",
    "from scipy.stats import chi2_contingency\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import ethnicolr\n",
    "from ethnicolr import pred_census_ln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File Paths\n",
    "absolute_path = \"C:\\\\Users\\\\tykun\\\\\\OneDrive\\\\Documents\\\\SchoolDocs\\VSCodeProjects\\\\connectedData\\\\board_analysis\\\\\"\n",
    "altered_dataframes = \"altered_dataframes\\\\\"\n",
    "gpt_dataframes = \"gpt_dataframes\\\\\"\n",
    "graphs = \"graphs\\\\\"\n",
    "scripts =  \"scripts\\\\\"\n",
    "board_dataframes = \"board_dataframes\\\\\"\n",
    "temporary = \"temporary_data\\\\\"\n",
    "\n",
    "altered_dataframe_path = f\"{absolute_path}{altered_dataframes}\"\n",
    "gpt_dataframe_path = f\"{absolute_path}{gpt_dataframes}\" \n",
    "graph_path = f\"{absolute_path}{graphs}\"\n",
    "script_path = f\"{absolute_path}{scripts}\"\n",
    "boards_path = f\"{absolute_path}{board_dataframes}\"\n",
    "temporary_data_path = f\"{absolute_path}{temporary}\"\n",
    "\n",
    "# Valid Years\n",
    "years = [\"1999\", \"2000\", \"2005\", \"2008\", \"2009\", \"2013\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Created Files\n",
    "diversity_statistics_path = f\"{altered_dataframe_path}diversity_statistics.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_name(full_name):\n",
    "    \"\"\"\n",
    "    Extracts the last name from a full name.\n",
    "\n",
    "    Args:\n",
    "        full_name (str): The full name of a person.\n",
    "\n",
    "    Returns:\n",
    "        str: The last name.\n",
    "    \"\"\"\n",
    "    full_name = HumanName(full_name)\n",
    "    return str(full_name.last)\n",
    "\n",
    "# Helper function to extract the first name from a full name\n",
    "def get_first_name(full_name):\n",
    "    \"\"\"\n",
    "    Extracts the first name from a full name.\n",
    "\n",
    "    Args:\n",
    "        full_name (str): The full name of a person.\n",
    "\n",
    "    Returns:\n",
    "        str: The first name.\n",
    "    \"\"\"\n",
    "    full_name = HumanName(full_name)\n",
    "    return str(full_name.first)\n",
    "\n",
    "# Classifies ethnicity into 'white', 'poc', or 'unknown'\n",
    "def classify_ethnicity(ethnicity):\n",
    "    \"\"\"\n",
    "    Classifies ethnicity into 'white', 'poc', or 'unknown'.\n",
    "\n",
    "    Args:\n",
    "        ethnicity (str): The ethnicity label.\n",
    "\n",
    "    Returns:\n",
    "        str: The classified ethnicity group.\n",
    "    \"\"\"\n",
    "    if ethnicity == 'white':\n",
    "        return 'white'\n",
    "    elif ethnicity in ['api', 'black', 'hispanic', 'aian']:\n",
    "        return 'poc'\n",
    "    else:\n",
    "        return 'unknown'\n",
    "\n",
    "# Classifies gender into 'male', 'female', or 'unknown'\n",
    "def classify_gender(gender_str):\n",
    "    \"\"\"\n",
    "    Classifies gender into 'male', 'female', or 'unknown'.\n",
    "\n",
    "    Args:\n",
    "        gender_str (str): The raw gender prediction string.\n",
    "\n",
    "    Returns:\n",
    "        str: The classified gender group.\n",
    "    \"\"\"\n",
    "    if gender_str in ['male', 'mostly_male']:\n",
    "        return 'male'\n",
    "    elif gender_str in ['female', 'mostly_female']:\n",
    "        return 'female'\n",
    "    else:\n",
    "        return 'unknown'\n",
    "\n",
    "# Predicts gender based on first names and adds a 'gender' column to the dataframe\n",
    "def pred_gender_fn(df, first_name_col):\n",
    "    \"\"\"\n",
    "    Predicts gender based on first names and classifies it.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The dataframe containing the first name column.\n",
    "        first_name_col (str): The column name containing first names.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The dataframe with a new 'gender' column.\n",
    "    \"\"\"\n",
    "    d = gender.Detector()\n",
    "    df['gender'] = df[first_name_col].apply(lambda x: d.get_gender(x))\n",
    "    df['gender'] = df['gender'].apply(classify_gender)\n",
    "    return df\n",
    "\n",
    "\n",
    "def classify_president_genders(valid_years, altered_dataframe_path):\n",
    "    \"\"\"\n",
    "    Classifies gender for each president in the specified years and adds a 'female_president' column.\n",
    "\n",
    "    Args:\n",
    "        valid_years (list): A list of years to process.\n",
    "        altered_dataframe_path (str): The path to the directory containing president CSV files.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary with 'Institution' as keys and 'female_president' as boolean values.\n",
    "    \"\"\"\n",
    "    president_data = {}\n",
    "\n",
    "    for year in valid_years:\n",
    "        president_df_path = f\"{altered_dataframe_path}{year}_presidents.csv\"\n",
    "        president_df = pd.read_csv(president_df_path)\n",
    "\n",
    "        # Extract first names and predict gender\n",
    "        president_df['first_name'] = president_df['Name'].apply(get_first_name)\n",
    "        president_df['gender'] = president_df['first_name'].apply(lambda x: gender.Detector().get_gender(x))\n",
    "        president_df['gender'] = president_df['gender'].apply(classify_gender)\n",
    "\n",
    "        # Add 'female_president' column\n",
    "        president_df['female_president'] = president_df['gender'].apply(lambda x: True if x == 'female' else False)\n",
    "\n",
    "        # Store results in a dictionary by Institution\n",
    "        for _, row in president_df.iterrows():\n",
    "            president_data[row['Institution']] = row['female_president']\n",
    "\n",
    "    return president_data\n",
    "\n",
    "def classify_president_genders(valid_years, altered_dataframe_path):\n",
    "    \"\"\"\n",
    "    Classifies gender for each president in the specified years and adds a 'female_president' column.\n",
    "\n",
    "    Args:\n",
    "        valid_years (list): A list of years to process.\n",
    "        altered_dataframe_path (str): The path to the directory containing president CSV files.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary with 'Institution' as keys and 'female_president' as boolean values.\n",
    "    \"\"\"\n",
    "    president_data = {}\n",
    "\n",
    "    for year in valid_years:\n",
    "        president_df_path = f\"{altered_dataframe_path}{year}_presidents.csv\"\n",
    "        president_df = pd.read_csv(president_df_path)\n",
    "\n",
    "        # Extract first names and predict gender\n",
    "        president_df['first_name'] = president_df['Name'].apply(get_first_name)\n",
    "        president_df['gender'] = president_df['first_name'].apply(lambda x: gender.Detector().get_gender(x))\n",
    "        president_df['gender'] = president_df['gender'].apply(classify_gender)\n",
    "\n",
    "        # Add 'female_president' column\n",
    "        president_df['female_president'] = president_df['gender'].apply(lambda x: True if x == 'female' else False)\n",
    "\n",
    "        # Store results in a dictionary by Institution\n",
    "        for _, row in president_df.iterrows():\n",
    "            president_data[row['Institution']] = row['female_president']\n",
    "\n",
    "    return president_data\n",
    "\n",
    "def process_board_data(valid_years):\n",
    "    \"\"\"\n",
    "    Processes board data for each year to compute ethnicity and gender counts, predicts president gender,\n",
    "    and adds 'female_president', 'poc_president', and 'AffiliationId' columns while retaining all original columns \n",
    "    and adding diversity change statistics, including 'total_members'.\n",
    "\n",
    "    Args:\n",
    "        valid_years (list): A list of years to process.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame with original columns, yearly change statistics, and added president and affiliation data.\n",
    "    \"\"\"\n",
    "    numbers_list = []\n",
    "\n",
    "    for year in valid_years:\n",
    "        # Load the president data for the current year\n",
    "        president_df_path = f\"{altered_dataframe_path}{year}_presidents.csv\"\n",
    "        president_df = pd.read_csv(president_df_path)\n",
    "\n",
    "        # Filter to include only schools with PrimarySample == True\n",
    "        president_df = president_df[president_df['PrimarySample'] == True]\n",
    "\n",
    "        # Extract first and last names and classify gender/ethnicity\n",
    "        president_df['first_name'] = president_df['Name'].apply(get_first_name)\n",
    "        president_df['last_name'] = president_df['Name'].apply(get_last_name)\n",
    "        president_df = pred_census_ln(president_df, 'last_name')\n",
    "        president_df = pred_gender_fn(president_df, 'first_name')\n",
    "\n",
    "        # Classify gender and ethnicity for president\n",
    "        president_df['female_president'] = president_df['gender'].apply(lambda x: True if x == 'female' else False)\n",
    "        president_df['poc_president'] = president_df['race'].apply(lambda x: True if x in ['api', 'black', 'hispanic', 'aian'] else False)\n",
    "\n",
    "        # Remove duplicates to ensure 'Institution' index is unique, keeping the first occurrence\n",
    "        president_df = president_df.drop_duplicates(subset='Institution').reset_index(drop=True)\n",
    "\n",
    "        # Create a dictionary for mapping institutions to 'female_president', 'poc_president', and 'AffiliationId' status\n",
    "        if president_df['Institution'].is_unique:\n",
    "            president_data = president_df.set_index('Institution')[['female_president', 'poc_president', 'AffiliationId']].to_dict('index')\n",
    "        else:\n",
    "            raise ValueError(\"Duplicate 'Institution' entries remain after deduplication.\")\n",
    "\n",
    "        # Load the board data for the current year\n",
    "        board_df_path = f\"{boards_path}{year}_boards.csv\"\n",
    "        board_df = pd.read_csv(board_df_path)\n",
    "\n",
    "        # Filter to include only schools with PrimarySample == True\n",
    "        board_df = board_df[board_df['PrimarySample'] == True]\n",
    "\n",
    "        # Extract first and last names for board members\n",
    "        board_df['first_name'] = board_df['Name'].apply(get_first_name)\n",
    "        board_df['last_name'] = board_df['Name'].apply(get_last_name)\n",
    "\n",
    "        # Predict ethnicity using the last name\n",
    "        board_df = pred_census_ln(board_df, 'last_name')\n",
    "\n",
    "        # Predict gender using the first name\n",
    "        board_df = pred_gender_fn(board_df, 'first_name')\n",
    "\n",
    "        # Classify ethnicity and gender\n",
    "        board_df['ethnicity_group'] = board_df['race'].apply(classify_ethnicity)\n",
    "        board_df['gender_group'] = board_df['gender']\n",
    "\n",
    "        # Compute ethnicity counts\n",
    "        ethnicity_counts = board_df.groupby(['Institution', 'carnegie_id', 'AffiliationId', 'ethnicity_group']).size().unstack('ethnicity_group', fill_value=0).reset_index()\n",
    "\n",
    "        # Compute gender counts\n",
    "        gender_counts = board_df.groupby(['Institution', 'carnegie_id', 'AffiliationId', 'gender_group']).size().unstack('gender_group', fill_value=0).reset_index()\n",
    "\n",
    "        # Merge ethnicity and gender counts\n",
    "        counts_df = pd.merge(ethnicity_counts, gender_counts, on=['Institution', 'carnegie_id', 'AffiliationId'], how='outer')\n",
    "\n",
    "        # Add a column for total members\n",
    "        counts_df['total_members'] = counts_df[['male', 'female', 'unknown']].sum(axis=1)\n",
    "\n",
    "        # Add 'Year' column\n",
    "        counts_df['Year'] = year\n",
    "\n",
    "        # Add 'female_president', 'poc_president', and 'AffiliationId' columns from pre-processed president data\n",
    "        counts_df['female_president'] = counts_df['Institution'].map(lambda inst: president_data.get(inst, {}).get('female_president', False))\n",
    "        counts_df['poc_president'] = counts_df['Institution'].map(lambda inst: president_data.get(inst, {}).get('poc_president', False))\n",
    "        counts_df['AffiliationId'] = counts_df['Institution'].map(lambda inst: president_data.get(inst, {}).get('AffiliationId', ''))\n",
    "\n",
    "        # Reorder columns for clarity\n",
    "        cols = ['Year', 'Institution', 'carnegie_id', 'AffiliationId', 'female_president', 'poc_president', 'total_members'] + [col for col in counts_df.columns if col not in ['Year', 'Institution', 'carnegie_id', 'AffiliationId', 'female_president', 'poc_president', 'total_members']]\n",
    "        counts_df = counts_df[cols]\n",
    "\n",
    "        # Append the processed data for the current year\n",
    "        numbers_list.append(counts_df)\n",
    "\n",
    "    # Concatenate data from all years and fill NaN values with zeros\n",
    "    numbers_df = pd.concat(numbers_list, ignore_index=True)\n",
    "    numbers_df.fillna(0, inplace=True)\n",
    "\n",
    "    # Sort values by 'Institution', 'carnegie_id', 'AffiliationId', and 'Year'\n",
    "    numbers_df.sort_values(by=['Institution', 'carnegie_id', 'AffiliationId', 'Year'], inplace=True)\n",
    "\n",
    "    # Calculate yearly changes for each ethnicity and gender group\n",
    "    ethnicity_columns = ['poc', 'white', 'unknown']  # Adjust based on actual column names\n",
    "    gender_columns = ['male', 'female', 'unknown']   # Adjust based on actual column names\n",
    "\n",
    "    for col in ethnicity_columns + gender_columns:\n",
    "        # Calculate the difference from the previous year for each institution and affiliation\n",
    "        numbers_df[col + '_change'] = numbers_df.groupby(['Institution', 'carnegie_id'])[col].diff()\n",
    "\n",
    "    # Sort values for clarity\n",
    "    numbers_df.sort_values(by=['Year', 'Institution'], inplace=True)\n",
    "\n",
    "    return numbers_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m university_board_statistics_df \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_board_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43myears\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[4], line 200\u001b[0m, in \u001b[0;36mprocess_board_data\u001b[1;34m(valid_years)\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;66;03m# if 'PrimarySample' in board_df.columns:\u001b[39;00m\n\u001b[0;32m    196\u001b[0m \u001b[38;5;66;03m#     board_df = board_df[board_df['PrimarySample'] == True]\u001b[39;00m\n\u001b[0;32m    197\u001b[0m \n\u001b[0;32m    198\u001b[0m \u001b[38;5;66;03m# Extract names & predict gender\u001b[39;00m\n\u001b[0;32m    199\u001b[0m board_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfirst_name\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m board_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mName\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(get_first_name)\n\u001b[1;32m--> 200\u001b[0m board_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlast_name\u001b[39m\u001b[38;5;124m'\u001b[39m]  \u001b[38;5;241m=\u001b[39m \u001b[43mboard_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mName\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mget_last_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    201\u001b[0m board_df \u001b[38;5;241m=\u001b[39m pred_gender_fn(board_df, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfirst_name\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    203\u001b[0m \u001b[38;5;66;03m# Group by Institution + whatever IDs exist\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\tykun\\OneDrive\\Documents\\SchoolDocs\\VSCodeProjects\\projectEnv\\Lib\\site-packages\\pandas\\core\\series.py:4924\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[0;32m   4789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4791\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4796\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4797\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4798\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4799\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4800\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4915\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4916\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   4917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4918\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4920\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4922\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m-> 4924\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\tykun\\OneDrive\\Documents\\SchoolDocs\\VSCodeProjects\\projectEnv\\Lib\\site-packages\\pandas\\core\\apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[0;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[1;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\tykun\\OneDrive\\Documents\\SchoolDocs\\VSCodeProjects\\projectEnv\\Lib\\site-packages\\pandas\\core\\apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[0;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[0;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[0;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[0;32m   1509\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32mc:\\Users\\tykun\\OneDrive\\Documents\\SchoolDocs\\VSCodeProjects\\projectEnv\\Lib\\site-packages\\pandas\\core\\base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[1;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[0;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[1;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\tykun\\OneDrive\\Documents\\SchoolDocs\\VSCodeProjects\\projectEnv\\Lib\\site-packages\\pandas\\core\\algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[1;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[0;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[0;32m   1747\u001b[0m     )\n",
      "File \u001b[1;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[4], line 11\u001b[0m, in \u001b[0;36mget_last_name\u001b[1;34m(full_name)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_last_name\u001b[39m(full_name):\n\u001b[0;32m      2\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m    Extracts the last name from a full name.\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;124;03m        str: The last name.\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m     full_name \u001b[38;5;241m=\u001b[39m \u001b[43mHumanName\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfull_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(full_name\u001b[38;5;241m.\u001b[39mlast)\n",
      "File \u001b[1;32mc:\\Users\\tykun\\OneDrive\\Documents\\SchoolDocs\\VSCodeProjects\\projectEnv\\Lib\\site-packages\\nameparser\\parser.py:110\u001b[0m, in \u001b[0;36mHumanName.__init__\u001b[1;34m(self, full_name, constants, encoding, string_format, initials_format, initials_delimiter, first, middle, last, title, suffix, nickname)\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munparsable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    109\u001b[0m     \u001b[38;5;66;03m# full_name setter triggers the parse\u001b[39;00m\n\u001b[1;32m--> 110\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfull_name\u001b[49m \u001b[38;5;241m=\u001b[39m full_name\n",
      "File \u001b[1;32mc:\\Users\\tykun\\OneDrive\\Documents\\SchoolDocs\\VSCodeProjects\\projectEnv\\Lib\\site-packages\\nameparser\\parser.py:486\u001b[0m, in \u001b[0;36mHumanName.full_name\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m    484\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, binary_type):\n\u001b[0;32m    485\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_full_name \u001b[38;5;241m=\u001b[39m value\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoding)\n\u001b[1;32m--> 486\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_full_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\tykun\\OneDrive\\Documents\\SchoolDocs\\VSCodeProjects\\projectEnv\\Lib\\site-packages\\nameparser\\parser.py:608\u001b[0m, in \u001b[0;36mHumanName.parse_full_name\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    601\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparts: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, parts)\n\u001b[0;32m    603\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(parts) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    604\u001b[0m \n\u001b[0;32m    605\u001b[0m     \u001b[38;5;66;03m# no commas, title first middle middle middle last suffix\u001b[39;00m\n\u001b[0;32m    606\u001b[0m     \u001b[38;5;66;03m#            part[0]\u001b[39;00m\n\u001b[1;32m--> 608\u001b[0m     pieces \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_pieces\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    609\u001b[0m     p_len \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(pieces)\n\u001b[0;32m    610\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, piece \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(pieces):\n",
      "File \u001b[1;32mc:\\Users\\tykun\\OneDrive\\Documents\\SchoolDocs\\VSCodeProjects\\projectEnv\\Lib\\site-packages\\nameparser\\parser.py:760\u001b[0m, in \u001b[0;36mHumanName.parse_pieces\u001b[1;34m(self, parts, additional_parts_count)\u001b[0m\n\u001b[0;32m    755\u001b[0m \u001b[38;5;66;03m# If part contains periods, check if it's multiple titles or suffixes\u001b[39;00m\n\u001b[0;32m    756\u001b[0m \u001b[38;5;66;03m# together without spaces if so, add the new part with periods to the\u001b[39;00m\n\u001b[0;32m    757\u001b[0m \u001b[38;5;66;03m# constants so they get parsed correctly later\u001b[39;00m\n\u001b[0;32m    758\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m part \u001b[38;5;129;01min\u001b[39;00m output:\n\u001b[0;32m    759\u001b[0m     \u001b[38;5;66;03m# if this part has a period not at the beginning or end\u001b[39;00m\n\u001b[1;32m--> 760\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mC\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mregexes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mperiod_not_at_end\u001b[49m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mC\u001b[38;5;241m.\u001b[39mregexes\u001b[38;5;241m.\u001b[39mperiod_not_at_end\u001b[38;5;241m.\u001b[39mmatch(part):\n\u001b[0;32m    761\u001b[0m         \u001b[38;5;66;03m# split on periods, any of the split pieces titles or suffixes?\u001b[39;00m\n\u001b[0;32m    762\u001b[0m         \u001b[38;5;66;03m# (\"Lt.Gov.\")\u001b[39;00m\n\u001b[0;32m    763\u001b[0m         period_chunks \u001b[38;5;241m=\u001b[39m part\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    764\u001b[0m         titles \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mfilter\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_title,  period_chunks))\n",
      "File \u001b[1;32mc:\\Users\\tykun\\OneDrive\\Documents\\SchoolDocs\\VSCodeProjects\\projectEnv\\Lib\\site-packages\\nameparser\\config\\__init__.py:133\u001b[0m, in \u001b[0;36mTupleManager.__getattr__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, attr):\n\u001b[1;32m--> 133\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget(attr)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "university_board_statistics_df = process_board_data(years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_affiliation_id(affiliation_df, university_board_statistics_df):\n",
    "    count_updates = 0  # Counter for the number of updates\n",
    "\n",
    "    for index, row in affiliation_df.iterrows():\n",
    "        institution = row['FullName']\n",
    "        affiliation_id = row['AffiliationId']\n",
    "        \n",
    "        # Get the number of matching rows before updating\n",
    "        matching_rows = university_board_statistics_df[\n",
    "            (university_board_statistics_df['Institution'] == institution) & \n",
    "            (university_board_statistics_df['AffiliationId'].isna())\n",
    "        ]\n",
    "        \n",
    "        # Update AffiliationId if matches are found\n",
    "        if not matching_rows.empty:\n",
    "            count_updates += len(matching_rows)\n",
    "            university_board_statistics_df.loc[\n",
    "                (university_board_statistics_df['Institution'] == institution) & \n",
    "                (university_board_statistics_df['AffiliationId'].isna()), 'AffiliationId'\n",
    "            ] = affiliation_id\n",
    "\n",
    "    # Print the total number of updates made\n",
    "    print(f\"Total AffiliationId entries updated: {count_updates}\")\n",
    "\n",
    "    return university_board_statistics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total AffiliationId entries updated: 0\n"
     ]
    }
   ],
   "source": [
    "affiliation_df = pd.read_csv(f\"{temporary_data_path}affiliation.csv\")\n",
    "university_board_statistics_df = map_affiliation_id(affiliation_df, university_board_statistics_df)\n",
    "university_board_statistics_df.to_csv(altered_dataframe_path + \"university_board_statistics.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projectEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
