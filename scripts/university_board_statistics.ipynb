{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter, defaultdict\n",
    "from matplotlib.lines import Line2D\n",
    "from nameparser import HumanName\n",
    "import gender_guesser.detector as gender\n",
    "from scipy.stats import chi2_contingency\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import ethnicolr\n",
    "from ethnicolr import pred_census_ln\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File Paths\n",
    "absolute_path = \"C:\\\\Users\\\\tykun\\\\\\OneDrive\\\\Documents\\\\SchoolDocs\\VSCodeProjects\\\\connectedData\\\\board_analysis\\\\\"\n",
    "altered_dataframes = \"altered_dataframes\\\\\"\n",
    "gpt_dataframes = \"gpt_dataframes\\\\\"\n",
    "graphs = \"graphs\\\\\"\n",
    "scripts =  \"scripts\\\\\"\n",
    "board_dataframes = \"board_dataframes\\\\\"\n",
    "temporary = \"temporary_data\\\\\"\n",
    "college_matching = \"college_matching\\\\\"\n",
    "\n",
    "altered_dataframe_path = f\"{absolute_path}{altered_dataframes}\"\n",
    "gpt_dataframe_path = f\"{absolute_path}{gpt_dataframes}\" \n",
    "graph_path = f\"{absolute_path}{graphs}\"\n",
    "script_path = f\"{absolute_path}{scripts}\"\n",
    "boards_path = f\"{absolute_path}{board_dataframes}\"\n",
    "temporary_data_path = f\"{absolute_path}{temporary}\"\n",
    "college_matching_path = f\"{absolute_path}{college_matching}\"\n",
    "\n",
    "# Valid Years\n",
    "years = [\"1999\", \"2000\", \"2005\", \"2007\", \"2008\", \"2009\", \"2011\", \"2013\", \"2018\"]\n",
    "\n",
    "diversity_statistics_path = f\"{altered_dataframe_path}diversity_statistics.csv\"\n",
    "carnegie_map = pd.read_csv(f\"{college_matching_path}carnegie_map_openalex.csv\")\n",
    "board_statistics = pd.read_csv(f\"{altered_dataframe_path}sample_board_statistics.csv\")\n",
    "classification_map = pd.read_csv(f\"{college_matching_path}cc_download.csv\")\n",
    "state_path = f\"{temporary_data_path}state_systems_validated.csv\"   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_name(full_name):\n",
    "    \"\"\"\n",
    "    Removes specified substrings and patterns from a full name.\n",
    "\n",
    "    Args:\n",
    "        full_name (str): The full name to clean.\n",
    "\n",
    "    Returns:\n",
    "        str: The cleaned full name.\n",
    "    \"\"\"\n",
    "    if not isinstance(full_name, str):  # Ensure the input is a string\n",
    "        return \"Unknown\"\n",
    "\n",
    "    # Substrings to remove\n",
    "    substrings_to_remove = [\"Rev.\", \"SJ\", \"Sister\", \"Brother\", \"Father\", \"OP\", \"The Very\", \"Sr.\", \"O.P.\",\"Very Rev.\", \"Br.\", \"Dr.\", \"Md.\", \"S.J.\", \"Very Rev\", \"M.D.\", \"O.P\", \"S.J\", \"J.R\", \"Jr.\", \"Jr \", \"III\"]\n",
    "\n",
    "    # Remove specified substrings\n",
    "    for substring in substrings_to_remove:\n",
    "        full_name = full_name.replace(substring, \"\")\n",
    "\n",
    "    # Remove any capital letter followed by a period and a space (e.g., \"J. \")\n",
    "    full_name = re.sub(r'\\b[A-Z]\\. ', '', full_name)\n",
    "\n",
    "    # Strip extra spaces\n",
    "    return full_name.strip()\n",
    "\n",
    "def get_last_name(full_name):\n",
    "    \"\"\"\n",
    "    Extracts the last name from a full name or returns the full name if extraction fails.\n",
    "\n",
    "    Args:\n",
    "        full_name (str): The full name of a person.\n",
    "\n",
    "    Returns:\n",
    "        str: The last name, or the full name if last name extraction fails.\n",
    "    \"\"\"\n",
    "    full_name = clean_name(full_name)\n",
    "    if not full_name or not full_name.strip():  # Check for None or empty strings\n",
    "        return str(full_name)\n",
    "    full_name = HumanName(full_name)\n",
    "    return str(full_name.last) if full_name.last else str(full_name)\n",
    "\n",
    "def get_first_name(full_name):\n",
    "    \"\"\"\n",
    "    Extracts the first name from a full name or returns the full name if extraction fails.\n",
    "\n",
    "    Args:\n",
    "        full_name (str): The full name of a person.\n",
    "\n",
    "    Returns:\n",
    "        str: The first name, or the full name if first name extraction fails.\n",
    "    \"\"\"\n",
    "    full_name = clean_name(full_name)\n",
    "    if not full_name or not full_name.strip():  # Check for None or empty strings\n",
    "        return str(full_name)\n",
    "    full_name = HumanName(full_name)\n",
    "    return str(full_name.first) if full_name.first else str(full_name)\n",
    "\n",
    "# Classifies ethnicity into 'white', 'poc', or 'unknown'\n",
    "def classify_ethnicity(ethnicity):\n",
    "    \"\"\"\n",
    "    Classifies ethnicity into 'white', 'poc', or 'unknown'.\n",
    "\n",
    "    Args:\n",
    "        ethnicity (str): The ethnicity label.\n",
    "\n",
    "    Returns:\n",
    "        str: The classified ethnicity group.\n",
    "    \"\"\"\n",
    "    if ethnicity == 'white':\n",
    "        return 'white'\n",
    "    elif ethnicity in ['api', 'black', 'hispanic', 'aian']:\n",
    "        return 'poc'\n",
    "    else:\n",
    "        return 'unknown'\n",
    "\n",
    "# Classifies gender into 'male', 'female', or 'unknown'\n",
    "def classify_gender(gender_str):\n",
    "    \"\"\"\n",
    "    Classifies gender into 'male', 'female', or 'unknown'.\n",
    "\n",
    "    Args:\n",
    "        gender_str (str): The raw gender prediction string.\n",
    "\n",
    "    Returns:\n",
    "        str: The classified gender group.\n",
    "    \"\"\"\n",
    "    if gender_str in ['male', 'mostly_male']:\n",
    "        return 'male'\n",
    "    elif gender_str in ['female', 'mostly_female']:\n",
    "        return 'female'\n",
    "    else:\n",
    "        return 'unknown'\n",
    "\n",
    "# Predicts gender based on first names and adds a 'gender' column to the dataframe\n",
    "def pred_gender_fn(df, first_name_col):\n",
    "    \"\"\"\n",
    "    Predicts gender based on first names and classifies it.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The dataframe containing the first name column.\n",
    "        first_name_col (str): The column name containing first names.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The dataframe with a new 'gender' column.\n",
    "    \"\"\"\n",
    "    d = gender.Detector()\n",
    "    df['gender'] = df[first_name_col].apply(lambda x: d.get_gender(x))\n",
    "    df['gender'] = df['gender'].apply(classify_gender)\n",
    "    return df\n",
    "\n",
    "\n",
    "def pred_census_ln_fn(df, last_name_col, year=2000):\n",
    "    \"\"\"\n",
    "    Predicts ethnicity based on last names and classifies it.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The dataframe containing the last name column.\n",
    "        last_name_col (str): The column name containing last names.\n",
    "        year (int): The year of the Census model to use for predictions.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The dataframe with a new 'ethnicity' column.\n",
    "    \"\"\"\n",
    "    # Ensure the last name column contains valid strings\n",
    "    df[last_name_col] = df[last_name_col].fillna(\"Unknown\").astype(str)\n",
    "\n",
    "    # Sanitize the last_name_col: Remove non-alphanumeric characters and trim whitespace\n",
    "    df[last_name_col] = df[last_name_col].apply(lambda x: ''.join(filter(str.isalnum, x)) if isinstance(x, str) else \"Unknown\")\n",
    "\n",
    "    # Use Ethnicolr to predict ethnicity\n",
    "    try:\n",
    "        df = pred_census_ln(df, last_name_col, year=year)\n",
    "    except ValueError as e:\n",
    "        print(f\"Error in Ethnicolr prediction: {e}\")\n",
    "        raise\n",
    "\n",
    "    # Extract the raw ethnicity prediction column\n",
    "    ethnicity_col = f\"{last_name_col}_pred_census_{year}\"\n",
    "    if ethnicity_col not in df.columns:\n",
    "        raise ValueError(f\"Expected column '{ethnicity_col}' missing after Ethnicolr prediction.\")\n",
    "\n",
    "    # Create the 'ethnicity' column and classify it\n",
    "    df['ethnicity'] = df[ethnicity_col].apply(classify_ethnicity)\n",
    "\n",
    "    # Drop the raw prediction column to keep only the classified 'ethnicity'\n",
    "    df.drop(columns=[ethnicity_col], inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def classify_president_genders(valid_years, altered_dataframe_path):\n",
    "    \"\"\"\n",
    "    Classifies gender for each president in the specified years and adds a 'female_president' column.\n",
    "\n",
    "    Args:\n",
    "        valid_years (list): A list of years to process.\n",
    "        altered_dataframe_path (str): The path to the directory containing president CSV files.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary with 'Institution' as keys and 'female_president' as boolean values.\n",
    "    \"\"\"\n",
    "    president_data = {}\n",
    "\n",
    "    for year in valid_years:\n",
    "        president_df_path = f\"{altered_dataframe_path}{year}_presidents.csv\"\n",
    "        president_df = pd.read_csv(president_df_path)\n",
    "\n",
    "        # Extract first names and predict gender\n",
    "        president_df['first_name'] = president_df['Name'].apply(get_first_name)\n",
    "        president_df['gender'] = president_df['first_name'].apply(lambda x: gender.Detector().get_gender(x))\n",
    "        president_df['gender'] = president_df['gender'].apply(classify_gender)\n",
    "\n",
    "        # Add 'female_president' column\n",
    "        president_df['female_president'] = president_df['gender'].apply(lambda x: True if x == 'female' else False)\n",
    "\n",
    "        # Store results in a dictionary by Institution\n",
    "        for _, row in president_df.iterrows():\n",
    "            president_data[row['Institution']] = row['female_president']\n",
    "\n",
    "    return president_data\n",
    "\n",
    "\n",
    "\n",
    "def process_board_data():\n",
    "    \"\"\"\n",
    "    Processes board data for each year to compute gender counts using both board_df and double_board_df,\n",
    "    predicts president gender, and adds 'female_president', 'AffiliationId', and 'PrimarySample' columns.\n",
    "    Retains original columns and adds membership counts, including 'total_members' and yearly changes.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame with original columns, yearly change statistics, and added\n",
    "                      president/affiliation data (for gender only).\n",
    "    \"\"\"\n",
    "    numbers_list = []\n",
    "\n",
    "    for year in years:\n",
    "        # Load the president data for the current year\n",
    "        president_df_path = f\"{altered_dataframe_path}{year}_presidents.csv\"\n",
    "        president_df = pd.read_csv(president_df_path)\n",
    "\n",
    "        # Extract names & predict gender\n",
    "        president_df['first_name'] = president_df['Name'].apply(get_first_name)\n",
    "        president_df['last_name'] = president_df['Name'].apply(get_last_name)\n",
    "        president_df = pred_gender_fn(president_df, 'first_name')\n",
    "\n",
    "        # Mark female_president\n",
    "        president_df['female_president'] = president_df['gender'].apply(lambda x: True if x == 'female' else False)\n",
    "\n",
    "        # Remove duplicates so each Institution is unique\n",
    "        president_df = president_df.drop_duplicates(subset='Institution').reset_index(drop=True)\n",
    "\n",
    "        # Create dictionary mapping institutions -> {female_president}\n",
    "        president_data = president_df.set_index('Institution')[['female_president']].to_dict('index')\n",
    "\n",
    "        # Load the board data for the current year\n",
    "        board_df_path = f\"{boards_path}{year}_boards.csv\"\n",
    "        board_df = pd.read_csv(board_df_path)\n",
    "\n",
    "        # Load the double board data for the current year\n",
    "        double_board_df_path = f\"{boards_path}{year}_double_board.csv\"\n",
    "        double_board_df = pd.read_csv(double_board_df_path)\n",
    "\n",
    "        # Function to preprocess and compute gender counts\n",
    "        def preprocess_and_count(df):\n",
    "            # Extract names & predict gender\n",
    "            df['first_name'] = df['Name'].apply(get_first_name)\n",
    "            df['last_name'] = df['Name'].apply(get_last_name)\n",
    "            df = pred_gender_fn(df, 'first_name')\n",
    "\n",
    "            # Check for 'PrimarySample' column\n",
    "            if 'PrimarySample' in df.columns:\n",
    "                primary_sample_map = df.drop_duplicates(subset='Institution').set_index('Institution')['PrimarySample']\n",
    "            else:\n",
    "                # If 'PrimarySample' doesn't exist, assume False for all\n",
    "                primary_sample_map = pd.Series(False, index=df['Institution'].unique())\n",
    "\n",
    "            # Group by Institution and AffiliationId and gender\n",
    "            group_cols = ['Institution', 'AffiliationId']\n",
    "            gender_counts = (\n",
    "                df.groupby(group_cols + ['gender'])\n",
    "                  .size()\n",
    "                  .unstack('gender', fill_value=0)\n",
    "                  .reset_index()\n",
    "            )\n",
    "\n",
    "            # Ensure all gender columns are present\n",
    "            for col in ['male', 'female', 'unknown']:\n",
    "                if col not in gender_counts.columns:\n",
    "                    gender_counts[col] = 0\n",
    "\n",
    "            # Add total_members from male/female/unknown columns\n",
    "            gender_counts['total_members'] = gender_counts[['male', 'female', 'unknown']].sum(axis=1)\n",
    "\n",
    "            # Map PrimarySample\n",
    "            gender_counts['PrimarySample'] = gender_counts['Institution'].map(primary_sample_map).fillna(False)\n",
    "\n",
    "            return gender_counts\n",
    "\n",
    "        # Preprocess and count for board_df\n",
    "        board_gender_counts = preprocess_and_count(board_df)\n",
    "        board_gender_counts.rename(columns={\n",
    "            'male': 'male_board',\n",
    "            'female': 'female_board',\n",
    "            'unknown': 'unknown_board',\n",
    "            'total_members': 'total_members_board'\n",
    "        }, inplace=True)\n",
    "\n",
    "        # Preprocess and count for double_board_df\n",
    "        double_board_gender_counts = preprocess_and_count(double_board_df)\n",
    "        double_board_gender_counts.rename(columns={\n",
    "            'male': 'male_double',\n",
    "            'female': 'female_double',\n",
    "            'unknown': 'unknown_double',\n",
    "            'total_members': 'total_members_double'\n",
    "        }, inplace=True)\n",
    "\n",
    "        # Merge the two gender counts DataFrames\n",
    "        merged_gender_counts = pd.merge(\n",
    "            board_gender_counts,\n",
    "            double_board_gender_counts,\n",
    "            on=['Institution', 'AffiliationId', 'PrimarySample'],\n",
    "            how='outer',\n",
    "            suffixes=('_board', '_double')\n",
    "        )\n",
    "\n",
    "        # Fill NaN values with 0 for gender counts\n",
    "        for col in ['male_board', 'female_board', 'unknown_board', 'total_members_board',\n",
    "                    'male_double', 'female_double', 'unknown_double', 'total_members_double']:\n",
    "            if col in merged_gender_counts.columns:\n",
    "                merged_gender_counts[col] = merged_gender_counts[col].fillna(0)\n",
    "            else:\n",
    "                merged_gender_counts[col] = 0\n",
    "\n",
    "        # Compute weighted average for overlapping institutions\n",
    "        # Define functions to compute weighted averages\n",
    "        def weighted_avg(row, col_board, col_double):\n",
    "            total = row['total_members_board'] + row['total_members_double']\n",
    "            if total == 0:\n",
    "                return 0\n",
    "            return round(\n",
    "                (row[col_board] * row['total_members_board'] +\n",
    "                 row[col_double] * row['total_members_double']) / total\n",
    "            )\n",
    "\n",
    "        # Apply weighted averages for each gender and cast to int\n",
    "        merged_gender_counts['male'] = merged_gender_counts.apply(\n",
    "            lambda row: int(weighted_avg(row, 'male_board', 'male_double')), axis=1\n",
    "        )\n",
    "        merged_gender_counts['female'] = merged_gender_counts.apply(\n",
    "            lambda row: int(weighted_avg(row, 'female_board', 'female_double')), axis=1\n",
    "        )\n",
    "        merged_gender_counts['unknown'] = merged_gender_counts.apply(\n",
    "            lambda row: int(weighted_avg(row, 'unknown_board', 'unknown_double')), axis=1\n",
    "        )\n",
    "        merged_gender_counts['total_members'] = merged_gender_counts.apply(\n",
    "            lambda row: int(row['total_members_board'] + row['total_members_double']), axis=1\n",
    "        )\n",
    "\n",
    "        # Add 'Year' column\n",
    "        merged_gender_counts['Year'] = year\n",
    "\n",
    "        # Add 'female_president' column\n",
    "        merged_gender_counts['female_president'] = merged_gender_counts['Institution'].map(\n",
    "            lambda inst: president_data.get(inst, {}).get('female_president', False)\n",
    "        )\n",
    "\n",
    "        # Reorder and select relevant columns\n",
    "        main_cols = ['Year', 'Institution', 'AffiliationId', 'female_president', 'PrimarySample', 'total_members']\n",
    "        other_cols = ['male', 'female', 'unknown']\n",
    "        counts_df = merged_gender_counts[main_cols + other_cols]\n",
    "\n",
    "        numbers_list.append(counts_df)\n",
    "\n",
    "    # Concatenate data from all years\n",
    "    numbers_df = pd.concat(numbers_list, ignore_index=True)\n",
    "    numbers_df.fillna(0, inplace=True)\n",
    "\n",
    "    # Sort\n",
    "    numbers_df.sort_values(by=['Institution', 'AffiliationId', 'Year'], inplace=True)\n",
    "\n",
    "    # Calculate yearly changes for gender columns\n",
    "    gender_columns = ['male', 'female', 'unknown']\n",
    "    for col in gender_columns:\n",
    "        numbers_df[col + '_change'] = numbers_df.groupby(['Institution', 'AffiliationId'])[col].diff().fillna(0).astype(int)\n",
    "\n",
    "    # Final sort\n",
    "    numbers_df.sort_values(by=['Year', 'Institution'], inplace=True)\n",
    "\n",
    "    return numbers_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tykun\\AppData\\Local\\Temp\\ipykernel_17844\\4275046941.py:256: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  gender_counts['PrimarySample'] = gender_counts['Institution'].map(primary_sample_map).fillna(False)\n",
      "C:\\Users\\tykun\\AppData\\Local\\Temp\\ipykernel_17844\\4275046941.py:256: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  gender_counts['PrimarySample'] = gender_counts['Institution'].map(primary_sample_map).fillna(False)\n",
      "C:\\Users\\tykun\\AppData\\Local\\Temp\\ipykernel_17844\\4275046941.py:256: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  gender_counts['PrimarySample'] = gender_counts['Institution'].map(primary_sample_map).fillna(False)\n",
      "C:\\Users\\tykun\\AppData\\Local\\Temp\\ipykernel_17844\\4275046941.py:256: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  gender_counts['PrimarySample'] = gender_counts['Institution'].map(primary_sample_map).fillna(False)\n"
     ]
    }
   ],
   "source": [
    "university_board_statistics_df = process_board_data()\n",
    "university_board_statistics_df.to_csv(altered_dataframe_path + \"university_board_statistics.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_affiliation_id(affiliation_df, university_board_statistics_df):\n",
    "    count_updates = 0  # Counter for the number of updates\n",
    "\n",
    "    for index, row in affiliation_df.iterrows():\n",
    "        institution = row['FullName']\n",
    "        affiliation_id = row['AffiliationId']\n",
    "        \n",
    "        # Get the number of matching rows before updating\n",
    "        matching_rows = university_board_statistics_df[\n",
    "            (university_board_statistics_df['Institution'] == institution) & \n",
    "            (university_board_statistics_df['AffiliationId'].isna())\n",
    "        ]\n",
    "        \n",
    "        # Update AffiliationId if matches are found\n",
    "        if not matching_rows.empty:\n",
    "            count_updates += len(matching_rows)\n",
    "            university_board_statistics_df.loc[\n",
    "                (university_board_statistics_df['Institution'] == institution) & \n",
    "                (university_board_statistics_df['AffiliationId'].isna()), 'AffiliationId'\n",
    "            ] = affiliation_id\n",
    "\n",
    "    # Print the total number of updates made\n",
    "    print(f\"Total AffiliationId entries updated: {count_updates}\")\n",
    "\n",
    "    return university_board_statistics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tykun\\AppData\\Local\\Temp\\ipykernel_17844\\2976693132.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'Arizona Board of Regents' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  university_board_statistics.loc[\n"
     ]
    }
   ],
   "source": [
    "#combined a couple different scripts here so the variable names are slightly changed and makes code a bit messy \n",
    "\n",
    "\n",
    "university_board_statistics = university_board_statistics_df\n",
    "state_system_df = pd.read_csv(state_path)\n",
    "\n",
    "# Set default value of StateSystem to False\n",
    "university_board_statistics['StateSystem'] = False\n",
    "\n",
    "for index, row in state_system_df.iterrows():\n",
    "    if pd.notna(row['StateSystem']):\n",
    "        institution = row['Institution']\n",
    "        affiliation_id = row['AffiliationId']\n",
    "        state_system_value = row['StateSystem']\n",
    "        \n",
    "        university_board_statistics.loc[\n",
    "            (university_board_statistics['Institution'] == institution) | \n",
    "            (university_board_statistics['AffiliationId'] == affiliation_id), \n",
    "            'StateSystem'\n",
    "        ] = state_system_value\n",
    "\n",
    "university_board_statistics.to_csv(f\"{altered_dataframe_path}sample_board_statistics.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for year in years:\n",
    "#     # Load the data for the current year\n",
    "#     boards_df = pd.read_csv(f\"{boards_path}{year}_boards.csv\")\n",
    "    \n",
    "#     # Group by Institution and aggregate unique Name values into sets\n",
    "#     grouped = boards_df.groupby('Institution')['Name'].apply(set).reset_index()\n",
    "\n",
    "#     # Track processed institutions and new state system rows\n",
    "#     processed_institutions = set()\n",
    "#     new_state_system_rows = []\n",
    "\n",
    "#     # Create a mapping of name sets (as tuples) to lists of institutions that share them\n",
    "#     name_to_institutions = {}\n",
    "\n",
    "#     for i, group in grouped.iterrows():\n",
    "#         institution = group['Institution']\n",
    "#         names_set = tuple(group['Name'])  # Convert set to a tuple to make it hashable\n",
    "        \n",
    "#         # Group institutions by their name sets\n",
    "#         if names_set not in name_to_institutions:\n",
    "#             name_to_institutions[names_set] = []\n",
    "#         name_to_institutions[names_set].append(institution)\n",
    "\n",
    "#     # Process each group of institutions that share the same name set\n",
    "#     for names_set, institutions in name_to_institutions.items():\n",
    "#         if len(institutions) > 1:  # Only consider groups with duplicates\n",
    "#             processed_institutions.update(institutions)\n",
    "            \n",
    "#             # Check if any of the institutions have a state system value\n",
    "#             is_state_system = university_board_statistics.loc[\n",
    "#                 (university_board_statistics['Institution'].isin(institutions)) & \n",
    "#                 (university_board_statistics['StateSystem'].notna()) &\n",
    "#                 (university_board_statistics['StateSystem'] != False)\n",
    "#             ].any().any()\n",
    "\n",
    "#             if is_state_system:\n",
    "#                 # Extract the StateSystem value\n",
    "#                 state_system_name = university_board_statistics.loc[\n",
    "#                     (university_board_statistics['Institution'].isin(institutions)) & \n",
    "#                     (university_board_statistics['StateSystem'].notna()) &\n",
    "#                     (university_board_statistics['StateSystem'] != False), 'StateSystem'\n",
    "#                 ].values[0]\n",
    "\n",
    "#                 # Use one of the institutions' diversity statistics\n",
    "#                 source_stats = university_board_statistics.loc[\n",
    "#                     (university_board_statistics['Institution'].isin(institutions)) & \n",
    "#                     (university_board_statistics['Year'] == int(year))\n",
    "#                 ]\n",
    "\n",
    "#                 if not source_stats.empty:\n",
    "#                     source_stats = source_stats.iloc[0]\n",
    "#                     new_row = {\n",
    "#                         'Year': int(year),\n",
    "#                         'Institution': state_system_name,\n",
    "#                         'carnegie_id': np.nan,\n",
    "#                         'AffiliationId': np.nan,\n",
    "#                         'female_president': source_stats['female_president'],\n",
    "#                         # 'poc_president': source_stats['poc_president'],\n",
    "#                         # 'poc': source_stats['poc'],\n",
    "#                         # 'white': source_stats['white'],\n",
    "#                         'female': source_stats['female'],\n",
    "#                         'male': source_stats['male'],\n",
    "#                         'unknown': source_stats['unknown'],\n",
    "#                         # 'poc_change': source_stats['poc_change'],\n",
    "#                         # 'white_change': source_stats['white_change'],\n",
    "#                         'unknown_change': source_stats['unknown_change'],\n",
    "#                         'male_change': source_stats['male_change'],\n",
    "#                         'female_change': source_stats['female_change'],\n",
    "#                         'StateSystem': True\n",
    "#                     }\n",
    "#                     new_state_system_rows.append(new_row)\n",
    "\n",
    "#     # Remove duplicate entries from the university statistics\n",
    "#     university_board_statistics = university_board_statistics[\n",
    "#         ~((university_board_statistics['Institution'].isin(processed_institutions)) & \n",
    "#           (university_board_statistics['Year'] == int(year)))\n",
    "#     ]\n",
    "\n",
    "#     # Append new state system rows, if any\n",
    "#     if new_state_system_rows:\n",
    "#         new_rows_df = pd.DataFrame(new_state_system_rows)\n",
    "#         university_board_statistics = pd.concat([university_board_statistics, new_rows_df], ignore_index=True)\n",
    "#         print(f\"Replaced {len(processed_institutions)} duplicate entries with state system rows for year {year}.\")\n",
    "\n",
    "# # Save the updated dataframe to CSV\n",
    "# university_board_statistics = university_board_statistics.sort_values(by = [\"Year\", \"Institution\"])\n",
    "# university_board_statistics.to_csv(f\"{altered_dataframe_path}sample_board_statistics.csv\", index=False)\n",
    "# print(\"Updated university_board_statistics saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Merged board_statistics DataFrame:\n",
      "      Year                      Institution  AffiliationId  female_president  \\\n",
      "0     1999     Abilene Christian University     60205797.0             False   \n",
      "1     1999               Adelphi University     71965598.0             False   \n",
      "2     1999              Agnes Scott College     64506506.0              True   \n",
      "3     1999                   Albion College     45644089.0             False   \n",
      "4     1999                Alfred University     49502546.0             False   \n",
      "...    ...                              ...            ...               ...   \n",
      "5223  2018  Worcester Polytechnic Institute    107077323.0              True   \n",
      "5224  2018                Xavier University    194120229.0             False   \n",
      "5225  2018   Xavier University Of Louisiana    169251466.0             False   \n",
      "5226  2018                  Yale University     32971472.0             False   \n",
      "5227  2018               Yeshiva University     19772626.0             False   \n",
      "\n",
      "     PrimarySample  total_members  female  male  unknown  male_change  \\\n",
      "0            False           84.0      12    65        7          NaN   \n",
      "1             True           17.0       3    13        1          NaN   \n",
      "2            False           29.0      12    14        3          NaN   \n",
      "3            False           31.0       4    26        1          NaN   \n",
      "4            False           29.0       7    22        0          NaN   \n",
      "...            ...            ...     ...   ...      ...          ...   \n",
      "5223          True           29.0       9    20        0         -3.0   \n",
      "5224         False           36.0       8    27        1          1.0   \n",
      "5225         False           19.0       8     9        2          0.0   \n",
      "5226          True           19.0       7    10        2         -2.0   \n",
      "5227          True           38.0       5    29        4         -3.0   \n",
      "\n",
      "      female_change  unknown_change StateSystem     region  carnegie_id state  \\\n",
      "0               NaN             NaN       False      South     222178.0    TX   \n",
      "1               NaN             NaN       False  Northeast     188429.0    NY   \n",
      "2               NaN             NaN       False      South     138600.0    GA   \n",
      "3               NaN             NaN       False    Midwest     168546.0    MI   \n",
      "4               NaN             NaN       False  Northeast     188641.0    NY   \n",
      "...             ...             ...         ...        ...          ...   ...   \n",
      "5223            0.0             0.0       False  Northeast     168421.0    MA   \n",
      "5224            0.0             1.0       False    Midwest     206622.0    OH   \n",
      "5225           -2.0             1.0       False      South     160904.0    LA   \n",
      "5226            2.0             1.0       False  Northeast     130794.0    CT   \n",
      "5227           -2.0             1.0       False  Northeast     197708.0    NY   \n",
      "\n",
      "                     control  \n",
      "0     Private not-for-profit  \n",
      "1     Private not-for-profit  \n",
      "2     Private not-for-profit  \n",
      "3     Private not-for-profit  \n",
      "4     Private not-for-profit  \n",
      "...                      ...  \n",
      "5223  Private not-for-profit  \n",
      "5224  Private not-for-profit  \n",
      "5225  Private not-for-profit  \n",
      "5226  Private not-for-profit  \n",
      "5227  Private not-for-profit  \n",
      "\n",
      "[5228 rows x 17 columns]\n",
      "\n",
      "No Unnamed Columns Detected.\n"
     ]
    }
   ],
   "source": [
    "# -- Refactored Code --\n",
    "\n",
    "# 1. Remove any existing 'carnegie_id', 'state', 'control' columns\n",
    "board_statistics.drop(columns=['carnegie_id', 'state', 'control'], errors='ignore', inplace=True)\n",
    "\n",
    "# 2. Merge 'carnegie_id' from carnegie_map based on 'AffiliationId'\n",
    "board_statistics = board_statistics.merge(\n",
    "    carnegie_map[['AffiliationId', 'carnegie_id']], \n",
    "    on='AffiliationId', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# 3. Merge 'state' and 'control' from classification_map based on 'carnegie_id'\n",
    "board_statistics = board_statistics.merge(\n",
    "    classification_map[['unitid', 'state', 'control']], \n",
    "    left_on='carnegie_id', \n",
    "    right_on='unitid', \n",
    "    how='left', \n",
    "    suffixes=('', '_classification')\n",
    ")\n",
    "\n",
    "# 4. Drop the redundant 'unitid' column\n",
    "board_statistics.drop(columns='unitid', inplace=True)\n",
    "\n",
    "# 5. Rename columns if suffixes were added\n",
    "board_statistics.rename(\n",
    "    columns={'state_classification': 'state', 'control_classification': 'control'},\n",
    "    inplace=True\n",
    ")\n",
    "\n",
    "# 6. Remove any columns that start with \"Unnamed\"\n",
    "board_statistics = board_statistics.loc[:, ~board_statistics.columns.str.contains('^Unnamed')]\n",
    "\n",
    "# Final DataFrame Verification\n",
    "print(\"\\nMerged board_statistics DataFrame:\")\n",
    "print(board_statistics)\n",
    "\n",
    "# Check for (and confirm removal of) unnamed columns\n",
    "unnamed_columns = [col for col in board_statistics.columns if 'Unnamed' in col]\n",
    "if unnamed_columns:\n",
    "    print(\"\\nUnnamed Columns Detected and Removed:\")\n",
    "    print(unnamed_columns)\n",
    "else:\n",
    "    print(\"\\nNo Unnamed Columns Detected.\")\n",
    "\n",
    "\n",
    "board_statistics['control'] = board_statistics['control'].apply(\n",
    "    lambda x: 'Private' if 'Private' in str(x) else 'Public' if 'Public' in str(x) else x\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_to_region = {\n",
    "    # Northeast\n",
    "    \"CT\": \"Northeast\", \"ME\": \"Northeast\", \"MA\": \"Northeast\", \"NH\": \"Northeast\",\n",
    "    \"RI\": \"Northeast\", \"VT\": \"Northeast\", \"NJ\": \"Northeast\", \"NY\": \"Northeast\", \n",
    "    \"PA\": \"Northeast\", \"DC\": \"Northeast\",\n",
    "    \n",
    "    # Midwest\n",
    "    \"IL\": \"Midwest\", \"IN\": \"Midwest\", \"IA\": \"Midwest\", \"KS\": \"Midwest\",\n",
    "    \"MI\": \"Midwest\", \"MN\": \"Midwest\", \"MO\": \"Midwest\", \"NE\": \"Midwest\", \n",
    "    \"ND\": \"Midwest\", \"OH\": \"Midwest\", \"SD\": \"Midwest\", \"WI\": \"Midwest\",\n",
    "    \n",
    "    # South\n",
    "    \"AL\": \"South\", \"AR\": \"South\", \"DE\": \"South\", \"FL\": \"South\",\n",
    "    \"GA\": \"South\", \"KY\": \"South\", \"LA\": \"South\", \"MD\": \"South\",\n",
    "    \"MS\": \"South\", \"NC\": \"South\", \"OK\": \"South\", \"SC\": \"South\",\n",
    "    \"TN\": \"South\", \"TX\": \"South\", \"VA\": \"South\", \"WV\": \"South\",\n",
    "    \n",
    "    # West\n",
    "    \"AK\": \"West\", \"AZ\": \"West\", \"CA\": \"West\", \"CO\": \"West\",\n",
    "    \"HI\": \"West\", \"ID\": \"West\", \"MT\": \"West\", \"NV\": \"West\",\n",
    "    \"NM\": \"West\", \"OR\": \"West\", \"UT\": \"West\", \"WA\": \"West\",\n",
    "    \"WY\": \"West\"\n",
    "}\n",
    "# board_statistics[\"regoio\"]\n",
    "board_statistics['region'] = board_statistics['state'].map(state_to_region)\n",
    "board_statistics.to_csv(f\"{altered_dataframe_path}sample_board_statistics.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projectEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
