{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "import copy\n",
    "from nameparser import HumanName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "POSITION_BANK = [\"President\", \"Chancellor\", \"Provost\", \"Director\", \"Dean\", \"Controller\", \"Trustee\", \"Member\", \"Regent\", \"Chairman\", \"Overseer\", \"Assistant\", \"Librarian\", \"Secretary\", \"Chaplain\", \"Minister\", \"Treasurer\", \"Senior Counsel\", \"General Counsel\", \"Legal Counsel\", \"University Counsel\", \"College Counsel\", \"Special Counsel\", \"Corporation Counsel\", \"Officer\", \"Chief\", \"Professor\", \"Commissioner\", \"Fellow\", \"Chairperson\", \"Manager\", \"Clergy\", \"Coordinator\", \"Auditor\", \"Governor\", \"Representative\", \"Stockbroker\", \"Advisor\", \"Commandant\", \"Rector\", \"Attorney\", \"Curator\", \"Clerk\", \"Department Head\", \"Pastor\", \"Head\", \"Comptroller\", \"Deputy\", \"Inspector General\"]\n",
    "NON_BOARD_WORDS =[\"President\", \"Chancellor\", \"Provost\", \"Dean\", \"Controller\", \"Overseer\", \"Assistant\", \"Librarian\", \"Secretary\", \"Chaplain\", \"Minister\", \"Treasurer\", \"Senior Counsel\", \"General Counsel\", \"Legal Counsel\", \"University Counsel\", \"College Counsel\", \"Special Counsel\", \"Corporation Counsel\", \"Officer\", \"Chief\", \"Professor\", \"Commissioner\", \"Manager\", \"Clergy\", \"Coordinator\", \"Auditor\", \"Representative\", \"Stockbroker\", \"Advisor\", \"Commandant\", \"Rector\", \"Attorney\", \"Curator\", \"Clerk\", \"Department Head\", \"Pastor\", \"Head\", \"Comptroller\", \"Deputy\", \"Inspector General\", \"Vice\", \"Chancellor,\", \"President,\", \"Executive\", \"Affairs\", \"Senior\", \"Associate\", \"Administration\", \"University\", \"College\"]\n",
    "BOARD_WORDS = [\"Trustee\", \"Regent\", \"Member\", \"Fellow\", \"Overseer\", \"Governor\", \"Curator\", \"Visitor\", \"Manager\"]\n",
    "OTHER_BOARD_WORD = [\"President\", \"Chairman\", \"Chairperson\" ,\"Treasurer\", \"Rector\", \"Member\", \"Secretary\", \"Ex Officio\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File Paths\n",
    "absolute_path = \"C:\\\\Users\\\\tykun\\\\\\OneDrive\\\\Documents\\\\SchoolDocs\\VSCodeProjects\\\\connectedData\\\\board_analysis\\\\\"\n",
    "altered_dataframes = \"altered_dataframes\\\\\"\n",
    "gpt_dataframes = \"gpt_dataframes\\\\\"\n",
    "graphs = \"graphs\\\\\"\n",
    "scripts =  \"scripts\\\\\"\n",
    "board_dataframes = \"board_dataframes\\\\\"\n",
    "split_dataframes = \"split_dataframes\\\\\"\n",
    "temporary = \"temporary_data\\\\\"\n",
    "\n",
    "altered_dataframe_path = f\"{absolute_path}{altered_dataframes}\"\n",
    "gpt_dataframe_path = f\"{absolute_path}{gpt_dataframes}\" \n",
    "graph_path = f\"{absolute_path}{graphs}\"\n",
    "script_path = f\"{absolute_path}{scripts}\"\n",
    "boards_path = f\"{absolute_path}{board_dataframes}\"\n",
    "split_path = f\"{absolute_path}{split_dataframes}\"\n",
    "temporary_path = f\"{absolute_path}{temporary}\"\n",
    "\n",
    "# Valid Years\n",
    "years = [\"1999\", \"2000\", \"2005\", \"2008\", \"2009\", \"2013\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper functions\n",
    "def higher_ascii(char1, char2):    \n",
    "    if ord(char1.upper()) >= ord(char2.upper()):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def parse_name(raw_name):\n",
    "    raw = raw_name.replace(\"Rev\", \"\")\n",
    "    raw = raw.replace(\"Very \", \"\")\n",
    "    parsed_name = HumanName(raw)\n",
    "    parsed_name.suffix = \"\"\n",
    "    pre_parse = str(parsed_name)\n",
    "    split_name = pre_parse.split(\" \")\n",
    "    last_name = parsed_name.last\n",
    "    if last_name == \"\" or \" \" in last_name or last_name == '.':\n",
    "        return split_name[-1]\n",
    "    else:\n",
    "        return str(last_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_institutions(df):\n",
    "    \"\"\"\n",
    "    Extracts the names of all unique institutions from the given DataFrame.\n",
    "    Args:\n",
    "        df (pandas.DataFrame): The DataFrame containing institution data.\n",
    "    Returns:\n",
    "        list: A list of unique institution names.\n",
    "    \"\"\"\n",
    "    institution_list = []  # Initialize an empty list to store unique institution names\n",
    "    for index, row in df.iterrows():  # Iterate over each row in the DataFrame\n",
    "        if row[\"Institution\"] not in institution_list:  # Check if the institution is not already in the list\n",
    "            institution_list.append(row[\"Institution\"])  # Add the institution to the list\n",
    "    print(institution_list)  # Print the list of unique institutions\n",
    "    return institution_list  # Return the list of unique institutions\n",
    "\n",
    "\n",
    "def determine_board_position(df):\n",
    "    \"\"\"\n",
    "    Determines the most common board position names for each institution and identifies if there are multiple boards.\n",
    "    Args:\n",
    "        df (pandas.DataFrame): The DataFrame containing institution and position data.\n",
    "    Returns:\n",
    "        tuple: A tuple containing two dictionaries:\n",
    "            - most_frequent (dict): A dictionary where keys are institution names and values are the most common board position names.\n",
    "            - two_boards (dict): A dictionary where keys are institution names and values indicate the second most common board position name if there are multiple boards, otherwise None.\n",
    "    \"\"\"\n",
    "    most_frequent = {}  # Initialize an empty dictionary to store the most common board position for each institution\n",
    "    two_boards = {}  # Initialize an empty dictionary to store the second most common board position for each institution\n",
    "    grouped_df = df.groupby(\"Institution\")  # Group the DataFrame by institution\n",
    "    for key, value in grouped_df:  # Iterate over each group\n",
    "        word_count = Counter()  # Initialize a Counter to count the occurrences of board position words\n",
    "        for position in value[\"Position\"]:  # Iterate over each position in the group\n",
    "            if not pd.isna(position):  # Check if the position is not NaN\n",
    "                individual_words = position.split()  # Split the position into individual words\n",
    "            else:\n",
    "                individual_words = \"\"  # If the position is NaN, set individual_words to an empty string\n",
    "            filtered_words = [word for word in individual_words if word in BOARD_WORDS]  # Filter the words to include only those in BOARD_WORDS\n",
    "            word_count.update(filtered_words)  # Update the word count with the filtered words\n",
    "        if word_count:  # Check if there are any counted words\n",
    "            common_words = word_count.most_common(2)  # Get the two most common words\n",
    "            most_frequent[key] = common_words[0][0]  # Set the most common word as the most frequent board position for the institution\n",
    "            # If there are two board words that come up, and the second board word comes up frequently, it is likely a school with two boards\n",
    "            if len(common_words) >= 2:\n",
    "                large_enough_board = common_words[1][1] >= (common_words[0][1] / 4) or (common_words[0][1] >= 8)  # Check if the second most common word is frequent enough\n",
    "            else:\n",
    "                large_enough_board = False  # If there is only one common word, set large_enough_board to False\n",
    "            if len(common_words) >= 2 and large_enough_board and common_words[1][0] != \"Director\":  # Check if there are two common words, the second word is frequent enough, and it is not \"Director\"\n",
    "                if common_words[1][0].strip().lower() != common_words[0][0].strip().lower():  # Check if the second common word is not the same as the first common word\n",
    "                    two_boards[key] = common_words[1][0]  # Set the second common word as the second board position for the institution\n",
    "            else:\n",
    "                two_boards[key] = None  # If the conditions are not met, set the second board position to None\n",
    "    return most_frequent, two_boards  # Return the dictionaries of most frequent and second board positions\n",
    "\n",
    "\n",
    "def determine_director_schools(df):\n",
    "    \"\"\"\n",
    "    Determines the institutions where 'Director' is a common board position and identifies if there are multiple boards.\n",
    "    Args:\n",
    "        df (pandas.DataFrame): The DataFrame containing institution and position data.\n",
    "    Returns:\n",
    "        tuple: A tuple containing two dictionaries:\n",
    "            - most_frequent (dict): A dictionary where keys are institution names and values are the most common 'Director' position names.\n",
    "            - two_boards (dict): A dictionary where keys are institution names and values indicate the second most common 'Director' position name if there are multiple boards, otherwise None.\n",
    "    \"\"\"\n",
    "    most_frequent = {}\n",
    "    two_boards = {}\n",
    "    grouped_df = df.groupby(\"Institution\")\n",
    "    for key, value in grouped_df:\n",
    "        word_count = Counter()\n",
    "        for position in value[\"Position\"]:\n",
    "            individual_words = position.split()\n",
    "            board_words_dir = ['Director']\n",
    "            filtered_words = [word for word in individual_words if word in board_words_dir]\n",
    "            word_count.update(filtered_words)\n",
    "        if word_count:\n",
    "            common_words = word_count.most_common(2)\n",
    "            most_frequent[key] = common_words[0][0]\n",
    "            #if there are two board words that come up, and the second board word comes up frequently, likely is a school with two boards\n",
    "            if len(common_words) >= 2:\n",
    "                large_enough_board = common_words[1][1] >= (common_words[0][1] / 4) or (common_words[0][1] >= 8)\n",
    "            else:\n",
    "                large_enough_board = False\n",
    "            if len(common_words) >= 2 and large_enough_board:\n",
    "                if common_words[1][0].strip().lower() != common_words[0][0].strip().lower():\n",
    "                    two_boards[key] = common_words[1][0]\n",
    "            else:\n",
    "                two_boards[key] = None\n",
    "        else:\n",
    "            most_frequent[key] = None\n",
    "            two_boards[key] = None\n",
    "    return most_frequent, two_boards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method to determine the start and end indices of each board within the dataframe\n",
    "def find_word_grouping(df, board_name):\n",
    "    \"\"\"\n",
    "    Finds the start and end indices of each board in the given dataframe, based on the provided board names.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): The dataframe containing board information, indexed by \"Institution\" and \"Position\".\n",
    "        board_name (dict): A dictionary mapping institution names to specific board positions.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing:\n",
    "            - pd.DataFrame: A concatenated dataframe of the relevant board sections.\n",
    "            - dict: A dictionary of the first board occurrence indices per institution.\n",
    "            - dict: A dictionary of the last board occurrence indices per institution.\n",
    "            - dict: A dictionary of the first occurrence of each institution in the dataframe.\n",
    "    \"\"\"\n",
    "    grouped_df = df.groupby(\"Institution\")\n",
    "    first_board_occurrence, last_board_occurrence, first_institution_occurrence = {}, {}, {}\n",
    "    result_dataframe = []\n",
    "\n",
    "    for key, value in grouped_df:\n",
    "        board_position = board_name.get(key, None)\n",
    "        first_institution_occurrence[key] = value.index[0]\n",
    "\n",
    "        if board_position is not None:\n",
    "            all_members = value[\"Position\"].tolist()\n",
    "            try:\n",
    "                # Find the first and last index of the board position in the group\n",
    "                first_index = next(i for i, pos in enumerate(all_members) if board_position == pos.title())\n",
    "                last_index = len(all_members) - next(i for i, pos in enumerate(reversed(all_members)) if board_position in pos.title()) - 1\n",
    "                \n",
    "                first_board_occurrence[key] = value.index[first_index]\n",
    "                last_board_occurrence[key] = value.index[last_index]\n",
    "                result_dataframe.append(value.iloc[first_index:last_index + 1])\n",
    "            except StopIteration:\n",
    "                # If position is not found, default to the full range of the group\n",
    "                first_board_occurrence[key] = value.index[0]\n",
    "                last_board_occurrence[key] = value.index[-1]\n",
    "        else:\n",
    "            first_board_occurrence[key] = value.index[0]\n",
    "            last_board_occurrence[key] = value.index[-1]\n",
    "\n",
    "    return pd.concat(result_dataframe), first_board_occurrence, last_board_occurrence, first_institution_occurrence\n",
    "\n",
    "\n",
    "# Method to find board positions within the dataframe using substring matching\n",
    "def find_word_grouping_substring(df, board_name):\n",
    "    \"\"\"\n",
    "    Finds the start and end indices of each board in the given dataframe using substring matching for board names.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): The dataframe containing board information, indexed by \"Institution\" and \"Position\".\n",
    "        board_name (dict): A dictionary mapping institution names to specific board positions.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing:\n",
    "            - pd.DataFrame: A concatenated dataframe of the relevant board sections.\n",
    "            - dict: A dictionary of the first board occurrence indices per institution.\n",
    "            - dict: A dictionary of the last board occurrence indices per institution.\n",
    "            - dict: A dictionary of the first occurrence of each institution in the dataframe.\n",
    "    \"\"\"\n",
    "    grouped_df = df.groupby(\"Institution\")\n",
    "    first_board_occurrence, last_board_occurrence, first_institution_occurrence = {}, {}, {}\n",
    "    result_dataframe = []\n",
    "\n",
    "    for key, value in grouped_df:\n",
    "        board_position = board_name.get(key, None)\n",
    "        first_institution_occurrence[key] = value.index[0]\n",
    "\n",
    "        if board_position is not None:\n",
    "            all_members = value[\"Position\"].tolist()\n",
    "            try:\n",
    "                # Find the first and last index of the board position using substring matching\n",
    "                first_index = next(i for i, pos in enumerate(all_members) if board_position in pos.title())\n",
    "                last_index = len(all_members) - next(i for i, pos in enumerate(reversed(all_members)) if board_position in pos.title()) - 1\n",
    "                \n",
    "                first_board_occurrence[key] = value.index[first_index]\n",
    "                last_board_occurrence[key] = value.index[last_index]\n",
    "                result_dataframe.append(value.iloc[first_index:last_index + 1])\n",
    "            except StopIteration:\n",
    "                # If position is not found, default to the full range of the group\n",
    "                first_board_occurrence[key] = value.index[0]\n",
    "                last_board_occurrence[key] = value.index[-1]\n",
    "        else:\n",
    "            first_board_occurrence[key] = value.index[0]\n",
    "            last_board_occurrence[key] = value.index[-1]\n",
    "\n",
    "    return pd.concat(result_dataframe), first_board_occurrence, last_board_occurrence, first_institution_occurrence\n",
    "\n",
    "\n",
    "# Method to verify alphabetical ordering of names when expanding boards upwards\n",
    "def verify_ordering(full_df, current_board_start, count):\n",
    "    \"\"\"\n",
    "    Verifies that names are ordered alphabetically in ascending order when expanding a board upwards.\n",
    "\n",
    "    Args:\n",
    "        full_df (pd.DataFrame): The complete dataframe containing all board data.\n",
    "        current_board_start (int): The starting index of the current board in the dataframe.\n",
    "        count (int): Number of rows to check upwards.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the names are in correct alphabetical order, False otherwise.\n",
    "    \"\"\"\n",
    "    original_board_position = full_df.iloc[current_board_start]\n",
    "    original_last_name = parse_name(original_board_position[\"Name\"])\n",
    "\n",
    "    while count > 0:\n",
    "        current_position = full_df.iloc[current_board_start - count]\n",
    "        current_last_name = parse_name(current_position[\"Name\"])\n",
    "        correct_ordering = higher_ascii(original_last_name[0], current_last_name[0])\n",
    "        if not correct_ordering:\n",
    "            return False\n",
    "        count -= 1\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "# Method to expand a single board upwards within the dataframe\n",
    "def expand_single_board_upward(full_df, grouped_boards, board_indices_start):\n",
    "    \"\"\"\n",
    "    Expands a single board section upward by checking rows above the current board start index.\n",
    "\n",
    "    Args:\n",
    "        full_df (pd.DataFrame): The complete dataframe containing all board data.\n",
    "        grouped_boards (dict): Dictionary of grouped board dataframes by institution.\n",
    "        board_indices_start (dict): Dictionary of starting indices for each board.\n",
    "\n",
    "    Returns:\n",
    "        dict: Updated dictionary of grouped boards with expanded data.\n",
    "    \"\"\"\n",
    "    sorted_keys = sorted(board_indices_start.keys(), key=lambda k: board_indices_start[k])\n",
    "\n",
    "    for key in sorted_keys:\n",
    "        expanded_flag = False\n",
    "        count = 4  # Number of rows to expand upwards\n",
    "        current_board_start = board_indices_start[key]\n",
    "\n",
    "        while count > 0:\n",
    "            previous_df_row = full_df.iloc[current_board_start - count]\n",
    "            previous_row_position = previous_df_row[\"Position\"].title()\n",
    "            original_df_row = full_df.iloc[current_board_start]\n",
    "            original_row_position = original_df_row[\"Position\"].title()\n",
    "            same_institution = original_df_row[\"Institution\"] == key\n",
    "            board_position = any(p in previous_row_position for p in OTHER_BOARD_WORD)\n",
    "\n",
    "            if same_institution and (board_position or expanded_flag):\n",
    "                if not expanded_flag:\n",
    "                    alphabetical_order = verify_ordering(full_df, current_board_start, count)\n",
    "\n",
    "                if (alphabetical_order and \"Dean\" not in previous_row_position) or expanded_flag:\n",
    "                    grouped_boards[key] = pd.concat([pd.DataFrame([previous_df_row]), grouped_boards.get(key, pd.DataFrame())])\n",
    "                    expanded_flag = True\n",
    "\n",
    "            count -= 1\n",
    "\n",
    "    return grouped_boards\n",
    "\n",
    "\n",
    "def expand_double_board_upward(full_df, grouped_boards, board_indices_start, double_boards):\n",
    "    \"\"\"\n",
    "    Expands double board sections upwards by checking rows above the current board start index.\n",
    "\n",
    "    Args:\n",
    "        full_df (pd.DataFrame): The complete dataframe containing all board data.\n",
    "        grouped_boards (dict): Dictionary of grouped board dataframes by institution.\n",
    "        board_indices_start (dict): Dictionary of starting indices for each board.\n",
    "        double_boards (dict): Dictionary indicating which institutions have double boards.\n",
    "\n",
    "    Returns:\n",
    "        dict: Updated dictionary of grouped boards with expanded data.\n",
    "    \"\"\"\n",
    "    sorted_keys = sorted(board_indices_start.keys(), key=lambda k: board_indices_start[k])\n",
    "\n",
    "    for key in sorted_keys:\n",
    "        expanded_flag = False\n",
    "        count = 4  # Arbitrary value for the number of rows to expand upwards\n",
    "        current_board_start = board_indices_start[key]\n",
    "\n",
    "        while count > 0:\n",
    "            previous_df_row = full_df.iloc[current_board_start - count]\n",
    "            previous_row_position = previous_df_row[\"Position\"].title()\n",
    "            original_df_row = full_df.iloc[current_board_start]\n",
    "            same_institution = original_df_row[\"Institution\"] == key\n",
    "            board_position = any(p in previous_row_position for p in OTHER_BOARD_WORD)\n",
    "\n",
    "            if same_institution and (board_position or expanded_flag) and double_boards[key] is not None:\n",
    "                if not expanded_flag:\n",
    "                    # Verify alphabetical ordering of last names before expansion\n",
    "                    alphabetical_order = verify_ordering(full_df, current_board_start, count)\n",
    "\n",
    "                if (alphabetical_order and \"Dean\" not in previous_row_position) or expanded_flag:\n",
    "                    grouped_boards[key] = pd.concat([pd.DataFrame([previous_df_row]), grouped_boards.get(key, pd.DataFrame())])\n",
    "                    expanded_flag = True\n",
    "\n",
    "            count -= 1\n",
    "\n",
    "    return grouped_boards\n",
    "\n",
    "\n",
    "# Method to expand a single board section downwards within the dataframe\n",
    "def expand_single_board_downward(full_df, grouped_boards, board_indices_end, first_institution_index):\n",
    "    \"\"\"\n",
    "    Expands a single board section downward by checking rows below the current board end index.\n",
    "\n",
    "    Args:\n",
    "        full_df (pd.DataFrame): The complete dataframe containing all board data.\n",
    "        grouped_boards (dict): Dictionary of grouped board dataframes by institution.\n",
    "        board_indices_end (dict): Dictionary of ending indices for each board.\n",
    "        first_institution_index (dict): Dictionary indicating the first occurrence index of each institution.\n",
    "\n",
    "    Returns:\n",
    "        dict: Updated dictionary of grouped boards with expanded data.\n",
    "    \"\"\"\n",
    "    sorted_keys = sorted(board_indices_end.keys(), key=lambda k: board_indices_end[k])\n",
    "\n",
    "    for key in sorted_keys:\n",
    "        if sorted_keys.index(key) < len(sorted_keys) - 1:\n",
    "            current_board_end = board_indices_end[key]\n",
    "            next_key = sorted_keys[sorted_keys.index(key) + 1]\n",
    "            next_board_start = first_institution_index[next_key]\n",
    "\n",
    "            # Expand downwards only if within range\n",
    "            if (current_board_end + 3 >= next_board_start and current_board_end + 1 != next_board_start):\n",
    "                for index in range(current_board_end + 1, next_board_start):\n",
    "                    grouped_boards[key] = pd.concat([grouped_boards.get(key, pd.DataFrame()), pd.DataFrame([full_df.iloc[index]])])\n",
    "\n",
    "    return grouped_boards\n",
    "\n",
    "\n",
    "# Method to expand a double board section downwards within the dataframe\n",
    "def expand_double_board_downward(full_df, grouped_boards, double_board_indices_start, double_board_indices_end, \n",
    "                                 first_institution_index, first_board_indices_start, first_board_indices_end, double_boards):\n",
    "    \"\"\"\n",
    "    Expands double board sections downward by checking rows below the current board end index.\n",
    "\n",
    "    Args:\n",
    "        full_df (pd.DataFrame): The complete dataframe containing all board data.\n",
    "        grouped_boards (dict): Dictionary of grouped board dataframes by institution.\n",
    "        double_board_indices_start (dict): Dictionary of starting indices for double boards.\n",
    "        double_board_indices_end (dict): Dictionary of ending indices for double boards.\n",
    "        first_institution_index (dict): Dictionary indicating the first occurrence index of each institution.\n",
    "        first_board_indices_start (dict): Dictionary of starting indices for single boards.\n",
    "        first_board_indices_end (dict): Dictionary of ending indices for single boards.\n",
    "        double_boards (dict): Dictionary indicating which institutions have double boards.\n",
    "\n",
    "    Returns:\n",
    "        dict: Updated dictionary of grouped boards with expanded data.\n",
    "    \"\"\"\n",
    "    sorted_keys = sorted(double_board_indices_end.keys(), key=lambda k: double_board_indices_end[k])\n",
    "\n",
    "    for key in sorted_keys:\n",
    "        if sorted_keys.index(key) < len(sorted_keys) - 1 and double_boards[key] is not None:\n",
    "            current_board_end = double_board_indices_end[key]\n",
    "            next_key = sorted_keys[sorted_keys.index(key) + 1]\n",
    "            next_board_start = first_institution_index[next_key]\n",
    "            current_board_start = double_board_indices_start[key]\n",
    "            first_board_end = first_board_indices_end[key]\n",
    "            first_board_start = first_board_indices_start[key]\n",
    "\n",
    "            if (current_board_start > first_board_end) and (current_board_end + 3 >= next_board_start and current_board_end + 1 != next_board_start):\n",
    "                for index in range(current_board_end + 1, next_board_start):\n",
    "                    grouped_boards[key] = pd.concat([grouped_boards.get(key, pd.DataFrame()), pd.DataFrame([full_df.iloc[index]])])\n",
    "            elif current_board_start < first_board_end and (current_board_end + 3 >= next_board_start and current_board_end + 1 != next_board_start):\n",
    "                for index in range(current_board_end + 1, first_board_start):\n",
    "                    grouped_boards[key] = pd.concat([grouped_boards.get(key, pd.DataFrame()), pd.DataFrame([full_df.iloc[index]])])\n",
    "\n",
    "    return grouped_boards\n",
    "\n",
    "\n",
    "# Method to expand director board sections downwards within the dataframe\n",
    "def expand_director_board_downward(full_df, grouped_boards, board_indices_end, first_institution_index):\n",
    "    \"\"\"\n",
    "    Expands director board sections downward by checking rows below the current board end index.\n",
    "\n",
    "    Args:\n",
    "        full_df (pd.DataFrame): The complete dataframe containing all board data.\n",
    "        grouped_boards (dict): Dictionary of grouped board dataframes by institution.\n",
    "        board_indices_end (dict): Dictionary of ending indices for director boards.\n",
    "        first_institution_index (dict): Dictionary indicating the first occurrence index of each institution.\n",
    "\n",
    "    Returns:\n",
    "        dict: Updated dictionary of grouped boards with expanded data.\n",
    "    \"\"\"\n",
    "    sorted_keys = sorted(board_indices_end.keys(), key=lambda k: board_indices_end[k])\n",
    "\n",
    "    for key in sorted_keys:\n",
    "        if sorted_keys.index(key) < len(sorted_keys) - 1:\n",
    "            current_board_end = board_indices_end[key]\n",
    "            next_key = sorted_keys[sorted_keys.index(key) + 1]\n",
    "            next_board_start = first_institution_index[next_key]\n",
    "\n",
    "            # Limit the expansion range\n",
    "            if current_board_end + 3 < next_board_start:\n",
    "                next_board_start = current_board_end + 3\n",
    "\n",
    "            for index in range(current_board_end + 1, next_board_start):\n",
    "                grouped_boards[key] = pd.concat([grouped_boards.get(key, pd.DataFrame()), pd.DataFrame([full_df.iloc[index]])])\n",
    "                index += 1\n",
    "\n",
    "    return grouped_boards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_board(full_df, board_df, board_indices_start, board_indices_end, first_institution_index):\n",
    "    \"\"\"\n",
    "    Expands a single board section both upwards and downwards within the dataframe and removes duplicate rows.\n",
    "\n",
    "    Args:\n",
    "        full_df (pd.DataFrame): The complete dataframe containing all board data.\n",
    "        board_df (pd.DataFrame): The dataframe containing specific board sections to be expanded.\n",
    "        board_indices_start (dict): Dictionary of starting indices for each board.\n",
    "        board_indices_end (dict): Dictionary of ending indices for each board.\n",
    "        first_institution_index (dict): Dictionary indicating the first occurrence index of each institution.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A cleaned and expanded dataframe containing board data, with duplicates removed.\n",
    "    \"\"\"\n",
    "    initial_boards = list(set(board_df[\"Institution\"].values))\n",
    "    grouped_boards = {name: group for name, group in board_df.groupby(\"Institution\")}\n",
    "    grouped_boards = expand_single_board_upward(full_df, grouped_boards, board_indices_start)\n",
    "    grouped_boards = expand_single_board_downward(full_df, grouped_boards, board_indices_end, first_institution_index)\n",
    "    combined_boards = pd.concat(grouped_boards.values())\n",
    "    final_boards = list(set(combined_boards[\"Institution\"].values))\n",
    "    indices_to_drop = []\n",
    "\n",
    "    for index, row in combined_boards.iterrows():\n",
    "        inst = row[\"Institution\"]\n",
    "        if inst in final_boards and inst not in initial_boards:\n",
    "            indices_to_drop.append(index)\n",
    "\n",
    "    cleaned__df = combined_boards.drop(index=indices_to_drop).reset_index(drop=True)\n",
    "    return cleaned__df\n",
    "\n",
    "\n",
    "def expand_double_board(full_df, board_df, board_indices_start, board_indices_end, first_institution_index, double_boards, first_board_indices_start, first_board_indices_end):\n",
    "    \"\"\"\n",
    "    Expands double board sections both upwards and downwards within the dataframe.\n",
    "\n",
    "    Args:\n",
    "        full_df (pd.DataFrame): The complete dataframe containing all board data.\n",
    "        board_df (pd.DataFrame): The dataframe containing specific double board sections to be expanded.\n",
    "        board_indices_start (dict): Dictionary of starting indices for double boards.\n",
    "        board_indices_end (dict): Dictionary of ending indices for double boards.\n",
    "        first_institution_index (dict): Dictionary indicating the first occurrence index of each institution.\n",
    "        double_boards (dict): Dictionary indicating which institutions have double boards.\n",
    "        first_board_indices_start (dict): Dictionary of starting indices for single boards.\n",
    "        first_board_indices_end (dict): Dictionary of ending indices for single boards.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: An expanded dataframe containing double board data.\n",
    "    \"\"\"\n",
    "    grouped_boards = {name: group for name, group in board_df.groupby(\"Institution\")}\n",
    "    grouped_boards = expand_double_board_upward(full_df, grouped_boards, board_indices_start, double_boards)\n",
    "    grouped_boards = expand_double_board_downward(full_df, grouped_boards, board_indices_start, board_indices_end, first_institution_index, first_board_indices_start, first_board_indices_end, double_boards)\n",
    "    combined_boards = pd.concat(grouped_boards.values())\n",
    "    return combined_boards\n",
    "\n",
    "\n",
    "def expand_directors(full_df, board_df, board_indices_start, board_indices_end, first_institution_index):\n",
    "    \"\"\"\n",
    "    Expands director board sections both upwards and downwards within the dataframe.\n",
    "\n",
    "    Args:\n",
    "        full_df (pd.DataFrame): The complete dataframe containing all board data.\n",
    "        board_df (pd.DataFrame): The dataframe containing specific director board sections to be expanded.\n",
    "        board_indices_start (dict): Dictionary of starting indices for director boards.\n",
    "        board_indices_end (dict): Dictionary of ending indices for director boards.\n",
    "        first_institution_index (dict): Dictionary indicating the first occurrence index of each institution.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: An expanded dataframe containing director board data.\n",
    "    \"\"\"\n",
    "    grouped_boards = {name: group for name, group in board_df.groupby(\"Institution\")}\n",
    "    grouped_boards = expand_single_board_upward(full_df, grouped_boards, board_indices_start)\n",
    "    grouped_boards = expand_director_board_downward(full_df, grouped_boards, board_indices_end, first_institution_index)\n",
    "    combined_boards = pd.concat(grouped_boards.values())\n",
    "    return combined_boards\n",
    "\n",
    "\n",
    "def assemble_board_dict(board_df):\n",
    "    \"\"\"\n",
    "    Assembles a dictionary where each key is an institution and the value is the corresponding dataframe subset.\n",
    "\n",
    "    Args:\n",
    "        board_df (pd.DataFrame): The dataframe containing board data, with \"Institution\" as a column.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary mapping each institution to its subset of the board dataframe.\n",
    "    \"\"\"\n",
    "    board_dict = {}\n",
    "    for institution in board_df['Institution'].unique():\n",
    "        rows = board_df[board_df[\"Institution\"] == institution]\n",
    "        board_dict[institution] = rows\n",
    "    return board_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning + Deletion\n",
    "\n",
    "def clean_false_members(expanded_boards, university_boards, original_boards):\n",
    "    \"\"\"\n",
    "    Removes false members from the expanded board dataframe based on specific position criteria.\n",
    "\n",
    "    Args:\n",
    "        expanded_boards (pd.DataFrame): The dataframe containing expanded board data.\n",
    "        university_boards (pd.DataFrame): The original university boards dataframe.\n",
    "        original_boards (pd.DataFrame): The original board data before expansion.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A cleaned dataframe with rows containing certain positions (e.g., \"Dean\" or \"Director\") removed.\n",
    "    \"\"\"\n",
    "    indices_to_drop = []\n",
    "    for index, row in expanded_boards.iterrows():\n",
    "        pos = row[\"Position\"]\n",
    "        if \"Dean\" in pos or \"Director\" in pos:\n",
    "            indices_to_drop.append(index)\n",
    "    cleaned__df = expanded_boards.drop(index=indices_to_drop).reset_index(drop=True)\n",
    "    return cleaned__df\n",
    "\n",
    "\n",
    "def delete_overlap(primary_boards, secondary_boards):\n",
    "    \"\"\"\n",
    "    Deletes rows in the secondary board dataframe that overlap with the primary board dataframe.\n",
    "\n",
    "    Args:\n",
    "        primary_boards (pd.DataFrame): The primary board dataframe to check for overlaps.\n",
    "        secondary_boards (pd.DataFrame): The secondary board dataframe to remove overlapping rows from.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The modified secondary board dataframe with overlapping rows removed.\n",
    "    \"\"\"\n",
    "    for index, row in secondary_boards.iterrows():\n",
    "        if any(row.equals(primary_row) for _, primary_row in primary_boards.iterrows()):\n",
    "            secondary_boards.drop(index, inplace=True)\n",
    "    return secondary_boards\n",
    "\n",
    "\n",
    "def validate_double_boards(board_dict, double_boards):\n",
    "    \"\"\"\n",
    "    Validates if rows in the double boards dataframe exist within the original board dictionary.\n",
    "\n",
    "    Args:\n",
    "        board_dict (dict): A dictionary where keys are institutions and values are their respective board dataframes.\n",
    "        double_boards (pd.DataFrame): The dataframe containing double board data to validate.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of invalid institutions found in the double boards dataframe.\n",
    "    \"\"\"\n",
    "    invalid_list = []\n",
    "    for index, row in double_boards.iterrows():\n",
    "        institution = row[\"Institution\"]\n",
    "        if institution in board_dict:\n",
    "            original_board = board_dict[institution]\n",
    "            is_row_in_df = original_board.apply(lambda x: x.equals(row), axis=1).any()\n",
    "            if is_row_in_df and institution not in invalid_list:\n",
    "                print(f\"Invalid board: {institution}\")\n",
    "                invalid_list.append(institution)\n",
    "    return invalid_list\n",
    "\n",
    "\n",
    "def verify_ordering_entire_board(full_df):\n",
    "    \"\"\"\n",
    "    Verifies the alphabetical ordering of the last names in the entire board dataframe and marks rows for removal if ordering issues are found.\n",
    "\n",
    "    Args:\n",
    "        full_df (pd.DataFrame): The complete dataframe containing all board data.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A modified dataframe with rows that do not follow alphabetical ordering removed.\n",
    "    \"\"\"\n",
    "    indices_to_remove = set()\n",
    "    for key, group in full_df.groupby('Institution'):\n",
    "        if len(group) <= 4:\n",
    "            indices_to_remove.update(group.index)\n",
    "            continue\n",
    "        count = 0\n",
    "        previous_last_name = \"000\"\n",
    "        for i, row in group.iterrows():\n",
    "            name = row[\"Name\"]\n",
    "            current_last_name = parse_name(name)\n",
    "            correct_ordering = higher_ascii(current_last_name[0], previous_last_name[0])\n",
    "            if not correct_ordering and count <= 2:\n",
    "                print(key, name, \"  \", previous_last_name)\n",
    "                indices_to_remove.add(i - 1)\n",
    "            count += 1\n",
    "            previous_last_name = current_last_name\n",
    "    print(\"here \", indices_to_remove)\n",
    "    modified_df = full_df.drop(index=list(indices_to_remove))\n",
    "    modified_df.reset_index(drop=True, inplace=True)\n",
    "    return modified_df\n",
    "\n",
    "\n",
    "def clean_false_members_directors(df):\n",
    "    \"\"\"\n",
    "    Removes false members from the dataframe based on specific position criteria related to directors.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The dataframe containing board data.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A cleaned dataframe with rows containing positions like \"Dean\" or \"Director\" removed.\n",
    "    \"\"\"\n",
    "    indices_to_drop = []\n",
    "    for index, row in df.iterrows():\n",
    "        pos = row[\"Position\"]\n",
    "        if \"Dean\" in pos or \"Director,\" in pos:\n",
    "            indices_to_drop.append(index)\n",
    "    cleaned__df = df.drop(index=indices_to_drop).reset_index(drop=False)\n",
    "    return cleaned__df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mark board members, presidents, chairmans, etc\n",
    "#currently not marking student reps as normal members\n",
    "CHAIRPERSONS = [\"Chairman\", \"Chairperson\", \"President\", \"Chair\", \"Chancellor\"]\n",
    "MEMBERS = [\"Trustee\", \"Regent\", \"Member\", \"Fellow\", \"Overseer\", \"Governor\", \"Curator\", \"Visitor\", \"Manager\", \"Director\"]\n",
    "OTHER_BOARD_WORD = [\"Treasurer\", \"Faculty Representative\", \"Rector\", \"Secretary\", \"Counsel\", \"Clerk\", \"Vacant\", \"Executive Committee Member\", \"Special\", \"Student\", \"Chief Executive Officer\", \"Affiliation\", \"Justice\", \"Registrar\", \"Staff Representative\", \"Librarian\",\n",
    "                    \"Alumni Representative\", \"Faculty Visitor\", \"Chief Investment Officer\"]\n",
    "\n",
    "def mark_members(board_df, university_boards):\n",
    "    board_df[\"FixedPosition\"] = \"\"\n",
    "    grouped_boards = board_df.groupby(\"Institution\")\n",
    "    for key, value in grouped_boards:\n",
    "        for index, row in value.iterrows():\n",
    "            position = row[\"Position\"].title()\n",
    "            board_name = university_boards[key]\n",
    "            pres_appears = any(pos in position for pos in CHAIRPERSONS)\n",
    "            if board_name is None:\n",
    "                board_name = \"zZbkjlhz01\" \n",
    "\n",
    "            if board_name in row[\"Position\"]:\n",
    "                board_df.at[index, \"FixedPosition\"] = board_name\n",
    "            elif  pres_appears and \"Vice\" not in position:\n",
    "                board_df.at[index, \"FixedPosition\"] = \"Board President\"\n",
    "            elif pres_appears and \"Vice\" in position:\n",
    "                board_df.at[index, \"FixedPosition\"] = \"Board Vice President\"\n",
    "            elif any(pos in position for pos in OTHER_BOARD_WORD):\n",
    "                board_df.at[index, \"FixedPosition\"] = \"Other Board Member\"\n",
    "            else:\n",
    "                board_df.at[index, \"FixedPosition\"] = board_name\n",
    "\n",
    "            if \"Ex Officio\" in row[\"Position\"]:\n",
    "                board_df.at[index, \"FixedPosition\"] += \", Ex Officio\"\n",
    "    return board_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove (dash, comma, period from system inst dict for better matching)\n",
    "def clean_system_inst_dict(full_df, state_systems):\n",
    "    \"\"\"\n",
    "    Cleans the system institution dictionary by removing dashes, commas, and periods from the keys.\n",
    "\n",
    "    Args:\n",
    "        system_inst_dict (dict): The original system institution dictionary.\n",
    "\n",
    "    Returns:\n",
    "        dict: The cleaned system institution dictionary.\n",
    "    \"\"\"\n",
    "    id_dict = {}\n",
    "    for index, row in full_df.iterrows():\n",
    "        id_dict[row[\"Institution\"]] = row[\"AffiliationId\"]\n",
    "\n",
    "    #mark state system boards \n",
    "    system_id_dict = {}\n",
    "    system_inst_dict = {}\n",
    "    for index, row in state_systems.iterrows():\n",
    "        if not pd.isna(row[\"StateSystem\"]):\n",
    "            system_id_dict[row[\"AffiliationId\"]] = row[\"StateSystem\"] \n",
    "            system_inst_dict[row[\"Institution\"]] = row[\"StateSystem\"]\n",
    "\n",
    "    #remove (dash, comma, period from system inst dict for better matching)\n",
    "    system_inst_dict_cleaned = {\n",
    "        key.replace(\"-\", \" \").replace(\",\", \"\").replace(\".\", \"\"): value\n",
    "        for key, value in system_inst_dict.items()\n",
    "    }\n",
    "    return system_id_dict, system_id_dict, system_inst_dict_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def find_unmarked_boards(university_boards, full_first_board):\n",
    "    \"\"\"\n",
    "    Identifies schools with a board where the board position does not appear as an exact string.\n",
    "\n",
    "    Args:\n",
    "        university_boards (dict): Dictionary of university boards.\n",
    "        full_first_board (pd.DataFrame): DataFrame containing the first board information.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary of unmarked boards.\n",
    "    \"\"\"\n",
    "    unmarked_boards = {}\n",
    "    for key, value in university_boards.items():\n",
    "        if value is not None and key not in full_first_board[\"Institution\"].values:\n",
    "            unmarked_boards[key] = value\n",
    "            print(key + \": \", value)\n",
    "    return unmarked_boards\n",
    "\n",
    "def create_system_dicts(state_systems):\n",
    "    \"\"\"\n",
    "    Creates dictionaries for mapping state system information.\n",
    "    \n",
    "    Args:\n",
    "        state_systems (pd.DataFrame): The dataframe containing state system data.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: Contains cleaned system ID dictionary and system institution dictionary.\n",
    "    \"\"\"\n",
    "    system_id_dict = {}\n",
    "    system_inst_dict = {}\n",
    "\n",
    "    for index, row in state_systems.iterrows():\n",
    "        if not pd.isna(row[\"StateSystem\"]):\n",
    "            system_id_dict[row[\"AffiliationId\"]] = row[\"StateSystem\"]\n",
    "            system_inst_dict[row[\"Institution\"]] = row[\"StateSystem\"]\n",
    "\n",
    "    return system_id_dict, system_inst_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Iterate through the years and create board dataframes for each year\n",
    "# state_systems = pd.read_csv(state_systems)\n",
    "# for year in years:\n",
    "#     print(year)\n",
    "#     # Load the dataframe for the current year\n",
    "#     df_path = f\"{split_path}{year}_split_positions.csv\"\n",
    "#     full_df = pd.read_csv(df_path)\n",
    "    \n",
    "#     system_id_dict, system_id_dict, system_inst_dict_cleaned = clean_system_inst_dict(full_df, state_systems)\n",
    "#     # Extract position titles for each institution \n",
    "#     university_boards, double_boards = determine_board_positions(full_df)\n",
    "\n",
    "#     #create original first board df\n",
    "#     institution_df = pd.DataFrame(columns=[\"Institution\", \"SubInstitution\", \"Category\"])\n",
    "#     original_single_boards, single_board_indices_start, single_board_indices_end, single_first_institution_index = find_word_grouping(full_df, university_boards)\n",
    "#     full_first_board = expand_board(full_df, original_single_boards, single_board_indices_start, single_board_indices_end, single_first_institution_index)\n",
    "#     full_first_board = clean_false_members(full_first_board, university_boards, original_single_boards)\n",
    "\n",
    "#     #identify the initial unmarked boards\n",
    "#     unmarked_boards = find_unmarked_boards(university_boards, full_first_board)\n",
    "\n",
    "#     #find the second boards\n",
    "#     original_double_boards, double_board_indices_start, double_board_indices_end, double_first_institution_index = find_word_grouping(full_df, double_boards)\n",
    "#     full_second_board = expand_double_board(full_df, original_double_boards, double_board_indices_start, double_board_indices_end, double_first_institution_index, double_boards, single_board_indices_start, single_board_indices_end)\n",
    "#     full_second_board = clean_false_members(full_second_board, double_boards, original_double_boards)\n",
    "\n",
    "#     #create initial board using substring position matching instead of exact matches\n",
    "#     substring_boards, substring_board_indices_start, substring_board_indices_end, substring_first_institution_index = find_word_grouping_substring(full_df, unmarked_boards)\n",
    "#     full_substring_board = expand_board(full_df, substring_boards, substring_board_indices_start, substring_board_indices_end, substring_first_institution_index)\n",
    "#     full_substring_board = clean_false_members(full_substring_board, unmarked_boards, substring_boards)\n",
    "\n",
    "#     #remove members based on alphabetical ordering of last names, remove names who didn't appear in order, then recreate df\n",
    "#     validated_substring_board = verify_ordering_entire_board(full_substring_board)\n",
    "#     validated_substring_df, validated_substring_indices_start, validated_substring_indices_end, validated_substring_first_inst_index = find_word_grouping_substring(validated_substring_board, unmarked_boards)\n",
    "#     validated_substring_board = expand_board(validated_substring_board, validated_substring_df, validated_substring_indices_start, validated_substring_indices_end, validated_substring_first_inst_index)\n",
    "#     validated_substring_board = clean_false_members(validated_substring_board, unmarked_boards, validated_substring_df)\n",
    "\n",
    "#     director_common, double_directors = determine_director_schools(full_df)\n",
    "#     director_inst_boards = {}\n",
    "#     for key, value in director_common.items():\n",
    "#         if university_boards[key] == None and value != None:\n",
    "#             # print(key)\n",
    "#             director_inst_boards[key] = value\n",
    "#     institutions_to_keep = list(director_inst_boards.keys())\n",
    "#     director_df = full_df[full_df['Institution'].isin(institutions_to_keep)]\n",
    "\n",
    "#     #create initial board using substring position matching instead of exact matches\n",
    "#     director_boards, director_board_indices_start, director_board_indices_end, director_first_institution_index = find_word_grouping(director_df, director_inst_boards)\n",
    "#     full_director_board = expand_directors(full_df, director_boards, director_board_indices_start, director_board_indices_end, director_first_institution_index)\n",
    "#     full_director_board = clean_false_members_directors(full_director_board)\n",
    "\n",
    "#     validated_director_board = verify_ordering_entire_board(full_director_board)\n",
    "#     validated_director_df, removed_director_indices_start, removed_director_indices_end, removed_director_institution_index = find_word_grouping(validated_director_board, director_inst_boards)\n",
    "#     final_director_board = expand_directors(validated_director_board, validated_director_df, removed_director_indices_start, removed_director_indices_end, removed_director_institution_index)\n",
    "#     final_director_board = clean_false_members_directors(final_director_board)\n",
    "\n",
    "#     grouped_dict = {key: value for key, value in final_director_board.groupby('Institution')}\n",
    "#     keys_to_remove = [institution for institution, group in grouped_dict.items() if group['Position'].str.contains('Director,', case=False).any()]\n",
    "#     # Remove the keys from the dictionary\n",
    "#     for key in keys_to_remove:\n",
    "#         del grouped_dict[key]\n",
    "#     final_director_board = pd.concat(grouped_dict.values()).reset_index(drop=True)\n",
    "\n",
    "#     insts = final_director_board[\"Institution\"].values\n",
    "#     for x in insts:\n",
    "#         university_boards[x] = \"Director\"\n",
    "\n",
    "#     #combine director, single, and substring board together\n",
    "#     combined_single_boards = pd.concat([full_first_board, validated_substring_board, final_director_board], ignore_index = True)\n",
    "\n",
    "#     grouped = combined_single_boards.groupby(\"Institution\")\n",
    "#     filtered_groups = {institution: group for institution, group in grouped if len(group) >= 4}\n",
    "#     filtered_combined_single_boards = pd.concat(filtered_groups.values()).reset_index(drop=True)\n",
    "\n",
    "#     filtered_combined_single_boards = filtered_combined_single_boards.sort_values(by=\"Institution\")\n",
    "\n",
    "#     #delete boards from the double board df which are just subsets of the single boards\n",
    "#     single_board_copy = filtered_combined_single_boards.copy(deep=True)\n",
    "#     board_dict = assemble_board_dict(single_board_copy)\n",
    "#     invalid_double_boards = validate_double_boards(board_dict, full_second_board)\n",
    "\n",
    "#     for index, row in full_second_board.iterrows():\n",
    "#         if row[\"Institution\"] in invalid_double_boards:\n",
    "#             full_second_board.drop(index, inplace=True)\n",
    "\n",
    "#     filtered_combined_single_boards[\"StateSystem\"] = \"\"\n",
    "#     id_name_dict = {}\n",
    "#     inst_name_list = []\n",
    "#     missing_institutions = []\n",
    "#     #mark state systems\n",
    "#     for index, row in filtered_combined_single_boards.iterrows():\n",
    "#         if row[\"AffiliationId\"] in system_id_dict:\n",
    "#             filtered_combined_single_boards.at[index, \"StateSystem\"] = system_id_dict[row[\"AffiliationId\"]]\n",
    "#     #add all ids and names\n",
    "#     for index, row in full_df.iterrows():\n",
    "#         inst = row[\"Institution\"]\n",
    "#         inst = inst.replace(\"-\", \" \").replace(\",\", \"\").replace(\".\", \"\")\n",
    "#         id_name_dict[inst] = row[\"AffiliationId\"]\n",
    "#         inst_name_list.append(inst)\n",
    "\n",
    "#     all_board_ids = list(set(np.concatenate((filtered_combined_single_boards[\"AffiliationId\"].values,  full_second_board[\"AffiliationId\"].values))))\n",
    "\n",
    "#     all_board_names = list(set(np.concatenate((filtered_combined_single_boards[\"Institution\"].values, full_second_board[\"Institution\"].values))))\n",
    "#     all_board_names_cleaned = []\n",
    "#     for name in all_board_names:\n",
    "#         name_cleaned = name.replace(\"-\", \" \").replace(\",\", \"\").replace(\".\", \"\")\n",
    "#         all_board_names_cleaned.append(name_cleaned)\n",
    "\n",
    "#     for inst, id in id_name_dict.items():\n",
    "#         if id not in all_board_ids and inst not in all_board_names_cleaned and id not in system_id_dict and inst not in system_inst_dict_cleaned:\n",
    "#             missing_institutions.append(inst)\n",
    "\n",
    "#     marked_boards_single_df = mark_members(filtered_combined_single_boards)\n",
    "#     marked_boards_single_df = marked_boards_single_df.drop_duplicates(keep = False)\n",
    "#     marked_boards_single_df.to_csv(board_path, index = False)\n",
    "\n",
    "#     marked_boards_double_df = mark_members(full_second_board)\n",
    "#     marked_boards_double_df = marked_boards_double_df.drop_duplicates(keep =False)\n",
    "#     marked_boards_double_df.to_csv(second_board_path, index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_year_data(year, split_path, state_systems):\n",
    "    \"\"\"\n",
    "    Processes the board data for a given year, including cleaning and marking.\n",
    "    \n",
    "    Args:\n",
    "        year (str): The year to process.\n",
    "        split_path (str): Path to the split CSV files.\n",
    "        state_systems (pd.DataFrame): The dataframe with state system data.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: Processed dataframes for single and double boards.\n",
    "    \"\"\"\n",
    "    # Load the dataframe for the current year\n",
    "    df_path = f\"{split_path}{year}_split_positions.csv\"\n",
    "    full_df = pd.read_csv(df_path)\n",
    "\n",
    "    # Create system dictionaries\n",
    "    system_id_dict, system_inst_dict_cleaned = create_system_dicts(state_systems)\n",
    "\n",
    "    # Extract position titles for each institution\n",
    "    university_boards, double_boards = determine_board_position(full_df)\n",
    "\n",
    "    # Create original first board dataframe\n",
    "    original_single_boards, single_board_indices_start, single_board_indices_end, single_first_institution_index = find_word_grouping(full_df, university_boards)\n",
    "    full_first_board = expand_board(full_df, original_single_boards, single_board_indices_start, single_board_indices_end, single_first_institution_index)\n",
    "    full_first_board = clean_false_members(full_first_board, university_boards, original_single_boards)\n",
    "\n",
    "    # Identify unmarked boards\n",
    "    unmarked_boards = find_unmarked_boards(university_boards, full_first_board)\n",
    "\n",
    "    # Process second boards\n",
    "    original_double_boards, double_board_indices_start, double_board_indices_end, double_first_institution_index = find_word_grouping(full_df, double_boards)\n",
    "    full_second_board = expand_double_board(full_df, original_double_boards, double_board_indices_start, double_board_indices_end, double_first_institution_index, double_boards, single_board_indices_start, single_board_indices_end)\n",
    "    full_second_board = clean_false_members(full_second_board, double_boards, original_double_boards)\n",
    "\n",
    "    # Process substring-based board positions\n",
    "    substring_boards, substring_board_indices_start, substring_board_indices_end, substring_first_institution_index = find_word_grouping_substring(full_df, unmarked_boards)\n",
    "    full_substring_board = expand_board(full_df, substring_boards, substring_board_indices_start, substring_board_indices_end, substring_first_institution_index)\n",
    "    full_substring_board = clean_false_members(full_substring_board, unmarked_boards, substring_boards)\n",
    "\n",
    "    # Validate substring board ordering\n",
    "    validated_substring_board = verify_ordering_entire_board(full_substring_board)\n",
    "    validated_substring_df, validated_substring_indices_start, validated_substring_indices_end, validated_substring_first_inst_index = find_word_grouping_substring(validated_substring_board, unmarked_boards)\n",
    "    validated_substring_board = expand_board(validated_substring_board, validated_substring_df, validated_substring_indices_start, validated_substring_indices_end, validated_substring_first_inst_index)\n",
    "    validated_substring_board = clean_false_members(validated_substring_board, unmarked_boards, validated_substring_df)\n",
    "\n",
    "    # Process director boards\n",
    "    director_common, double_directors = determine_director_schools(full_df)\n",
    "    director_inst_boards = {key: value for key, value in director_common.items() if university_boards[key] is None and value is not None}\n",
    "    director_df = full_df[full_df['Institution'].isin(director_inst_boards.keys())]\n",
    "\n",
    "    director_boards, director_board_indices_start, director_board_indices_end, director_first_institution_index = find_word_grouping(director_df, director_inst_boards)\n",
    "    full_director_board = expand_directors(full_df, director_boards, director_board_indices_start, director_board_indices_end, director_first_institution_index)\n",
    "    full_director_board = clean_false_members_directors(full_director_board)\n",
    "\n",
    "    # Validate director board ordering\n",
    "    validated_director_board = verify_ordering_entire_board(full_director_board)\n",
    "    validated_director_df, removed_director_indices_start, removed_director_indices_end, removed_director_institution_index = find_word_grouping(validated_director_board, director_inst_boards)\n",
    "    final_director_board = expand_directors(validated_director_board, validated_director_df, removed_director_indices_start, removed_director_indices_end, removed_director_institution_index)\n",
    "    final_director_board = clean_false_members_directors(final_director_board)\n",
    "\n",
    "    # Group and filter director boards\n",
    "    grouped_dict = {key: value for key, value in final_director_board.groupby('Institution')}\n",
    "    keys_to_remove = [institution for institution, group in grouped_dict.items() if group['Position'].str.contains('Director,', case=False).any()]\n",
    "    for key in keys_to_remove:\n",
    "        del grouped_dict[key]\n",
    "    final_director_board = pd.concat(grouped_dict.values()).reset_index(drop=True)\n",
    "\n",
    "    # Mark institutions with director boards\n",
    "    for x in final_director_board[\"Institution\"].values:\n",
    "        university_boards[x] = \"Director\"\n",
    "\n",
    "    # Combine single, substring, and director boards\n",
    "    combined_single_boards = pd.concat([full_first_board, validated_substring_board, final_director_board], ignore_index=True)\n",
    "    combined_single_boards = combined_single_boards.groupby(\"Institution\").filter(lambda x: len(x) >= 4).reset_index(drop=True)\n",
    "    combined_single_boards.sort_values(by=\"Institution\", inplace=True)\n",
    "\n",
    "    # Validate and clean double boards\n",
    "    board_dict = assemble_board_dict(combined_single_boards)\n",
    "    invalid_double_boards = validate_double_boards(board_dict, full_second_board)\n",
    "    full_second_board = full_second_board[~full_second_board[\"Institution\"].isin(invalid_double_boards)].reset_index(drop=True)\n",
    "\n",
    "    # Mark state systems and add additional attributes\n",
    "    combined_single_boards[\"StateSystem\"] = \"\"\n",
    "    for index, row in combined_single_boards.iterrows():\n",
    "        if row[\"AffiliationId\"] in system_id_dict:\n",
    "            combined_single_boards.at[index, \"StateSystem\"] = system_id_dict[row[\"AffiliationId\"]]\n",
    "\n",
    "    # Prepare lists for final checks\n",
    "    id_name_dict = {row[\"Institution\"].replace(\"-\", \" \").replace(\",\", \"\").replace(\".\", \"\"): row[\"AffiliationId\"] for _, row in full_df.iterrows()}\n",
    "    all_board_ids = list(set(np.concatenate((combined_single_boards[\"AffiliationId\"].values, full_second_board[\"AffiliationId\"].values))))\n",
    "    all_board_names = list(set(np.concatenate((combined_single_boards[\"Institution\"].values, full_second_board[\"Institution\"].values))))\n",
    "    all_board_names_cleaned = [name.replace(\"-\", \" \").replace(\",\", \"\").replace(\".\", \"\") for name in all_board_names]\n",
    "\n",
    "    missing_institutions = [inst for inst, id in id_name_dict.items() if id not in all_board_ids and inst not in all_board_names_cleaned and id not in system_id_dict and inst not in system_inst_dict_cleaned]\n",
    "\n",
    "    return combined_single_boards, full_second_board, missing_institutions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1999\n",
      "Birmingham Southern College:  Trustee\n",
      "Citadel:  Member\n",
      "Clemson University:  Member\n",
      "College Of Charleston:  Member\n",
      "College Of Staten Island:  Manager\n",
      "College Of William And Mary:  Member\n",
      "Concordia University:  Member\n",
      "Emory University:  Trustee\n",
      "George Mason University:  Member\n",
      "Grand Valley State University:  Member\n",
      "Idaho State University:  Member\n",
      "James Madison University:  Member\n",
      "Lamar State College Orange:  Manager\n",
      "Lamar University Port Arthur:  Manager\n",
      "Longwood College:  Member\n",
      "Mankato State University:  Trustee\n",
      "Michigan Technological University:  Member\n",
      "Montana Tech Of University Of Montana:  Manager\n",
      "Moorhead State University:  Trustee\n",
      "North Dakota University System:  Member\n",
      "Old Dominion University:  Member\n",
      "Radford University:  Member\n",
      "Saint Louis University:  Member\n",
      "State University Of New York At Albany:  Member\n",
      "State University Of New York At Brockport:  Member\n",
      "State University Of New York At Buffalo:  Member\n",
      "State University Of New York At Geneseo:  Member\n",
      "State University Of New York At Old Westbury:  Member\n",
      "State University Of New York At Oneonta:  Member\n",
      "State University Of New York At Oswego:  Member\n",
      "State University Of New York At Plattsburgh:  Member\n",
      "State University Of New York At Stony Brook:  Member\n",
      "Sweet Briar College:  Member\n",
      "Trinity College:  Trustee\n",
      "University Of Oregon:  Member\n",
      "University Of South Carolina:  Member\n",
      "University Of South Dakota:  Regent\n",
      "University Of Southern Colorado:  Member\n",
      "University Of Virginia:  Member\n",
      "Valparaiso University:  Member\n",
      "Virginia Commonwealth University:  Member\n",
      "Virginia Military Institute:  Member\n",
      "Virginia Polytechnic Institute And State University:  Member\n",
      "Winthrop University:  Trustee\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'California Maritime Academy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[55], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m year \u001b[38;5;129;01min\u001b[39;00m years:\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(year)\n\u001b[1;32m----> 6\u001b[0m     combined_single_boards, full_second_board, missing_institutions \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_year_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43myear\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate_systems\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;66;03m# Save outputs\u001b[39;00m\n\u001b[0;32m      8\u001b[0m     marked_boards_single_df \u001b[38;5;241m=\u001b[39m mark_members(combined_single_boards)\u001b[38;5;241m.\u001b[39mdrop_duplicates(keep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[54], line 33\u001b[0m, in \u001b[0;36mprocess_year_data\u001b[1;34m(year, split_path, state_systems)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Process second boards\u001b[39;00m\n\u001b[0;32m     32\u001b[0m original_double_boards, double_board_indices_start, double_board_indices_end, double_first_institution_index \u001b[38;5;241m=\u001b[39m find_word_grouping(full_df, double_boards)\n\u001b[1;32m---> 33\u001b[0m full_second_board \u001b[38;5;241m=\u001b[39m \u001b[43mexpand_double_board\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfull_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moriginal_double_boards\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdouble_board_indices_start\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdouble_board_indices_end\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdouble_first_institution_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdouble_boards\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msingle_board_indices_start\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msingle_board_indices_end\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m full_second_board \u001b[38;5;241m=\u001b[39m clean_false_members(full_second_board, double_boards, original_double_boards)\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# Process substring-based board positions\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[48], line 50\u001b[0m, in \u001b[0;36mexpand_double_board\u001b[1;34m(full_df, board_df, board_indices_start, board_indices_end, first_institution_index, double_boards, first_board_indices_start, first_board_indices_end)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;124;03mExpands double board sections both upwards and downwards within the dataframe.\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;124;03m    pd.DataFrame: An expanded dataframe containing double board data.\u001b[39;00m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     49\u001b[0m grouped_boards \u001b[38;5;241m=\u001b[39m {name: group \u001b[38;5;28;01mfor\u001b[39;00m name, group \u001b[38;5;129;01min\u001b[39;00m board_df\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInstitution\u001b[39m\u001b[38;5;124m\"\u001b[39m)}\n\u001b[1;32m---> 50\u001b[0m grouped_boards \u001b[38;5;241m=\u001b[39m \u001b[43mexpand_double_board_upward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfull_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrouped_boards\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mboard_indices_start\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdouble_boards\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m grouped_boards \u001b[38;5;241m=\u001b[39m expand_double_board_downward(full_df, grouped_boards, board_indices_start, board_indices_end, first_institution_index, first_board_indices_start, first_board_indices_end, double_boards)\n\u001b[0;32m     52\u001b[0m combined_boards \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(grouped_boards\u001b[38;5;241m.\u001b[39mvalues())\n",
      "Cell \u001b[1;32mIn[47], line 186\u001b[0m, in \u001b[0;36mexpand_double_board_upward\u001b[1;34m(full_df, grouped_boards, board_indices_start, double_boards)\u001b[0m\n\u001b[0;32m    183\u001b[0m same_institution \u001b[38;5;241m=\u001b[39m original_df_row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInstitution\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m key\n\u001b[0;32m    184\u001b[0m board_position \u001b[38;5;241m=\u001b[39m \u001b[38;5;28many\u001b[39m(p \u001b[38;5;129;01min\u001b[39;00m previous_row_position \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m OTHER_BOARD_WORD)\n\u001b[1;32m--> 186\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m same_institution \u001b[38;5;129;01mand\u001b[39;00m (board_position \u001b[38;5;129;01mor\u001b[39;00m expanded_flag) \u001b[38;5;129;01mand\u001b[39;00m \u001b[43mdouble_boards\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    187\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m expanded_flag:\n\u001b[0;32m    188\u001b[0m         \u001b[38;5;66;03m# Verify alphabetical ordering of last names before expansion\u001b[39;00m\n\u001b[0;32m    189\u001b[0m         alphabetical_order \u001b[38;5;241m=\u001b[39m verify_ordering(full_df, current_board_start, count)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'California Maritime Academy'"
     ]
    }
   ],
   "source": [
    "state_systems_path = f\"{temporary_path}state_systems_validated.csv\"\n",
    "state_systems = pd.read_csv(state_systems_path)\n",
    "\n",
    "for year in years:\n",
    "    print(year)\n",
    "    combined_single_boards, full_second_board, missing_institutions = process_year_data(year, split_path, state_systems)\n",
    "    # Save outputs\n",
    "    marked_boards_single_df = mark_members(combined_single_boards).drop_duplicates(keep=False)\n",
    "    marked_boards_single_df.to_csv(f\"{boards_path}{year}_single_board.csv\", index=False)\n",
    "    marked_boards_double_df = mark_members(full_second_board).drop_duplicates(keep=False)\n",
    "    marked_boards_double_df.to_csv(f\"{boards_path}{year}_double_board.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projectEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
